<!DOCTYPE html><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.6.0 for Hugo" />
  

  
  












  
  










  







  
  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Michaël Karpe" />

  
  
  
    
  
  <meta name="description" content="Image deblurring with Markov Random Fields" />

  
  <link rel="alternate" hreflang="en-us" href="https://michaelkarpe.github.io/computer-vision-projects/restoration/" />

  
  
  
    <meta name="theme-color" content="#3f51b5" />
  

  
  
    
    <script src="/js/mathjax-config.js"></script>
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.c7b8d9abd591ba2253ea42747e3ac3f5.css" media="print" onload="this.media='all'">

  
  
  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha512-W0xM4mr6dEP9nREo7Z9z+9X70wytKvMGeDsj7ps2+xg5QPrEBXC8tAW1IFnzjR6eoJ90JmCnFzerQJTLzIEHjA==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    
    
    
    
      
      
    
    
    

    
    
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.9c4c13a48bae91f201c0af6081455e43.css" />

  
  
  
  
  
  
  
    
    
    <link rel="stylesheet" href="/css/libs/chroma/github-light.min.css" title="hl-light" media="print" onload="this.media='all'" >
    <link rel="stylesheet" href="/css/libs/chroma/dracula.min.css" title="hl-dark" media="print" onload="this.media='all'" disabled>
  

  
  




<script async src="https://www.googletagmanager.com/gtag/js?id=G-695H905YSX"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url, target) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           if (target !== '_blank') {
             document.location = url;
           }
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target, event.target.getAttribute('target'));  
  }

  gtag('js', new Date());
  gtag('config', 'G-695H905YSX', {});
  gtag('set', {'cookie_flags': 'SameSite=None;Secure'});

  
  document.addEventListener('click', onClickCallback, false);
</script>


  


  


  




  
  
  

  
  

  
  
    <link rel="manifest" href="/manifest.webmanifest" />
  

  
  <link rel="icon" type="image/png" href="/media/icon_hu942ec82bbfdd4b8fc9bf90d8cd76fd06_20106_32x32_fill_lanczos_center_3.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hu942ec82bbfdd4b8fc9bf90d8cd76fd06_20106_180x180_fill_lanczos_center_3.png" />

  <link rel="canonical" href="https://michaelkarpe.github.io/computer-vision-projects/restoration/" />

  
  
  
  
  
  
  
  
    
  
  

  
  
    
    
  
  <meta property="twitter:card" content="summary_large_image" />
  
    <meta property="twitter:site" content="@wowchemy" />
    <meta property="twitter:creator" content="@wowchemy" />
  
  <meta property="og:site_name" content="Michaël Karpe" />
  <meta property="og:url" content="https://michaelkarpe.github.io/computer-vision-projects/restoration/" />
  <meta property="og:title" content="Markovian Image Restoration | Michaël Karpe" />
  <meta property="og:description" content="Image deblurring with Markov Random Fields" /><meta property="og:image" content="https://michaelkarpe.github.io/computer-vision-projects/restoration/featured.png" />
    <meta property="twitter:image" content="https://michaelkarpe.github.io/computer-vision-projects/restoration/featured.png" /><meta property="og:locale" content="en-us" />
  
    
      <meta
        property="article:published_time"
        content="2017-06-07T00:00:00&#43;00:00"
      />
    
    <meta property="article:modified_time" content="2017-06-07T00:00:00&#43;00:00">
  

  



  

  


  <title>Markovian Image Restoration | Michaël Karpe</title>

  
  
  
  











</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="becdb071f295cb06bab7b5f862303c2a" >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.1ee5462d74c6c0de1f8881b384ecc58d.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header">
    












<header class="header--fixed">
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/">Michaël Karpe</a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/">Michaël Karpe</a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-end" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#about"><span>Home</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#kaggle-competitions"><span>Kaggle Competitions</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#computer-vision-projects"><span>Computer Vision</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#machine-learning-projects"><span>Machine Learning</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#optimization-projects"><span>Optimization</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#programming-projects"><span>Programming</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#quantitative-finance-projects"><span>Quantitative Finance</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#publications"><span>Publications</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        
          
        

        
        

        
        
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    <article class="article">

  





















  
  


<div class="article-container pt-3">
  <h1>Markovian Image Restoration</h1>

  
  <p class="page-subtitle">Image deblurring with Markov Random Fields</p>
  

  


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      Michaël Karpe</span>, <span >
      Arnaud Sadaca</span>, <span >
      Nada Soussi</span>, <span >
      Claire Zeng</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    Jun 7, 2017
  </span>
  

  

  

  
  
  
  

  
  

</div>

  




<div class="btn-links mb-3">
  
  








  
    
  



<a class="btn btn-outline-primary btn-page-header" href="/computer-vision-projects/restoration/Report_Markovian_Image_Restoration.pdf" target="_blank" rel="noopener">
  PDF
</a>




  
  
    
  
<a class="btn btn-outline-primary btn-page-header" href="https://github.com/MichaelKarpe/ponts-paristech-projects/tree/master/computer-vision/markovian-image-restoration" target="_blank" rel="noopener">
  Code
</a>













  
  
  
    
  
  
  
  
  
    
    
      
    
  
  <a class="btn btn-outline-primary btn-page-header" href="/computer-vision-projects/restoration/Slides_Markovian_Image_Restoration.pdf" >
    Slides</a>


</div>


</div>


<div class="article-header article-container featured-image-wrapper mt-4 mb-4" style="max-width: 491px; max-height: 325px;">
  <div style="position: relative">
    <img src="/computer-vision-projects/restoration/featured_hu27d067da84df467a1cc44b138d7a3d58_13015_720x2500_fit_q75_h2_lanczos_3.webp" width="491" height="325" alt="" class="featured-image">
    
  </div>
</div>



  <div class="article-container">

    <div class="article-style">
      <p> </p>
<h1 id="presentation-of-the-project">Presentation of the project</h1>
<p>The acquisition of a digital image is most often accompanied by the appearance of noise, often due to imperfections in the detection, transmission or compression of the signal, or to inherent defects in the environment such as insufficient or too much lighting. The suppression of this noise is even a vital issue in several fields, including medical imaging, and the search for an effective image denoising algorithm remains a persistent challenge at the crossroads of several scientific fields: functional analysis, probability, statistics and physical sciences.</p>
<p>In this study, we implement different algorithms for the restitution of an image containing simple grayscale patterns, noisy according to Gaussian noise. For this, we adopt a probabilistic description of the image, considering its pixels as random variables $X_i$, energy $U(X_i)$ which depends on its neighborhood. This approach allows us to consider the image as a Markov field.</p>
<p> </p>
<h1 id="numerical-implementation-of-markov-fields">Numerical implementation of Markov fields</h1>
<p>We are now formulating the probabilistic methods that we have digitally implemented to apply them to image processing.</p>
<p>In our study, we will consider rectangular grayscale images (0 to 255), length $w$ and height $h$. Each pixel in the image is represented by its coordinates $(i, j)$ and a value corresponding to the gray level of the pixel, which value belongs to $E = [|0, 255|]$. The total image can thus be represented by an array of values of $E$, of dimension $w \times h$.</p>
<p>For each pixel, a click system can be defined as represented on the first image of this article. In our computer codes, the presence of a variable $c$ which will take the value $4$ or $8$ will allow us to choose if we consider $4$ or $8$-connected neighborhoods, and we will consider clicks of order $2$.</p>
<p>The implementation of image processing algorithms has three main phases:</p>
<ul>
<li>the choice of a suitable Markov field</li>
<li>the drawing of a configuration according to the chosen Markov field</li>
<li>the implementation of the algorithm that converges to a correct image after a certain number of prints.</li>
</ul>
<p>We describe these three phases in a theoretical way, then we will analyze the results obtained with the different methods.</p>
<p> </p>
<h2 id="markov-fields-in-image-processing">Markov fields in image processing</h2>
<p>We present here the most used Markov fields in image processing as well as some variants giving better results.</p>
<p> </p>
<h3 id="ising-model">Ising Model</h3>
<p>The Ising model is only applicable to an image with $2$ levels of gray. By an affine transformation, we can associate to these $2$ values the values of the set $E = \{-1, 1\}$. We recall the energy of this model:</p>
<p>$$U(x) = - \sum_{c=(s,t) \in C} \beta x_s x_t - \sum_{s \in S} B x_s$$</p>
<p> </p>
<h3 id="potts-model">Potts Model</h3>
<p>This is a generalization of Ising&rsquo;s model, adapted to a set $E$ of cardinal $N$, as $E = [|0, 255|]$. The main difference with the Ising model is that only potentials related to second-order clicks are defined. There is no energy term related to first-order clicks, corresponding to an external magnetic field. The energy of this model is :</p>
<p>$$U(x) = \ \beta \sum_{c=(s,t) \in C} (\textbf{1}<em>{\{x_s \neq x_t\}} - \textbf{1}</em>{\{x_s = x_t\}})$$</p>
<p>Such a model tends to create homogenous zones the larger the $\beta$ is.</p>
<p> </p>
<h3 id="gaussian-markovian-model">Gaussian Markovian model</h3>
<p>This model can only be used for grayscale images, which is perfectly suited to our study. We consider, here again, $4$- or $8$-axis neighborhoods and only second order clicks. The energy of this model is :</p>
<p>$$U(x) = \beta \sum_{c=(s,t) \in C} (x_s-x_t)^2 + \alpha \sum_{s \in S} (x_s-\mu_s)^2$$</p>
<p>For $\beta &gt; 0$, the first quadratic term favors small differences in gray level, since it minimizes an energy that increases quadratically with the difference in gray levels. The second term involves a $\mu_s$ term that corresponds to a reference image. If we know an approximation of the image we want to obtain, or if we want to remain close to the initial image, this term allows the solution image $x$ to not move away from the reference image $\mu$.</p>
<p> </p>
<h2 id="drawing-a-configuration-according-to-the-markov-field">Drawing a configuration according to the Markov field</h2>
<p>Once a Markov field has been chosen, its total energy must be minimized. This is done by pulling configurations. The general idea is to draw a random value for each pixel and to assign it this value if it allows the total energy to be reduced.</p>
<p>The algorithms most commonly used to make these draws, the Gibbs sampler and the Metropolis algorithm, work in a similar way. The $n$ iterations, where a $s$ pixel is randomly selected and then an image-dependent random experiment is associated with $s$ at the $n-1$ iteration. We update or not $s$ depending on the result of the random experiment.</p>
<p>Since all the pixels $s$ must be scanned a large number of times, one usually scans all the pixels line by line and from left to right without performing a random draw, to make sure that all pixels have been updated. The algorithm stops after a large number $n$ of iterations, or when there are few pixel changes for an iteration.</p>
<p>Both algorithms are called probabilistic relaxation algorithms: relaxation because the algorithm performs successive updates of the different pixels, and probabilistic because the algorithm simulates random draws.</p>
<p> </p>
<h3 id="gibbs-sampler">Gibbs&rsquo; sampler</h3>
<p>For each of the $n$ iterations of the algorithm, we scan all the pixels. For each pixel (noted $s$) :</p>
<ul>
<li>Calculation of the local probability, knowing the configuration of the neighbors $V_s$ for the image at iteration $n-1$ :</li>
</ul>
<p>$$ \mathbb{P} (X_s = x_s | V_s) = \dfrac{\exp (-U_s(x_s | V_s))}{\sum_{a_s \in A_s}{\exp (-U_s(a_s | V_s))}}$$</p>
<ul>
<li>Updating of the site by random draw according to the law $\mathbb{P}(X_s = x_s | V_s)$</li>
</ul>
<p> </p>
<h3 id="metropolis-algorithm">Metropolis algorithm</h3>
<p>For each of the $n$ iterations of the algorithm, we scan all the pixels. For each pixel (noted $s$) :</p>
<ul>
<li>Random draw of $\lambda$ in $E$ according to a uniform law on $E$:</li>
<li>Calculation of the energy variation if the value of $s$, $x_s^{(n-1)}$, is replaced by $\lambda$:
$$ \Delta U = U_s(\lambda | V_s^{(n-1)}) - U_s(x_s^{(n-1)} | V_s^{(n-1)}) $$</li>
<li>If $ \Delta U \leq $0, then we update the pixel: $x_s^{(n)} = \lambda$</li>
<li>Otherwise, update to the probability of success $p = \exp (- \Delta U)$</li>
</ul>
<p> </p>
<h2 id="implementation-of-the-image-restoration-algorithm">Implementation of the image restoration algorithm</h2>
<p>After implementing a configuration pull algorithm, it is necessary to implement an algorithm converging to a solution image of the total energy minimization problem. Two algorithms are mainly used in Markov field image processing.</p>
<p> </p>
<h3 id="simulated-annealing">Simulated annealing</h3>
<p>Simulated annealing is a classical method of energy minimization frequently used in physics. In image processing, the algorithm consists of $n$ iterations during which configuration prints are made. However, these prints now depend only on the configuration energy, but also on a quantity $T^{(n)}$ which measures the degree of randomness introduced in these prints, called temperature, and which decreases with each iteration. Starting from a fairly large temperature $T^{(0)}$ and the image to be processed, the algorithm is as follows:</p>
<p>For each iteration $n$,</p>
<ul>
<li>Printing a configuration by replacing the energies $U(x)$ by the quantities $U(x) / T^{(n)}$ for pixel update prints</li>
<li>Temperature decrease in logarithmic decay: $T^{(n)} &gt; \dfrac{c}{\log(2+n)}$</li>
</ul>
<p>Logarithmic decay is necessary to obtain the convergence in probability of the algorithm to the image that minimizes energy. In practice, for complex or large images, this decay is too slow and it is preferable to use a linear or quadratic decay, which can cause convergence to only a local minimum of energy. However, the size ($200 \times 200$ pixels) and the simplicity of the images we process allow us to use this logarithmic decay. Slight differences between logarithmic and linear decay have been observed, which is consistent with the notions of local and global energy minimum.</p>
<p> </p>
<h3 id="iterated-conditional-modes">Iterated conditional modes</h3>
<p>The <em>Iterated Conditional Modes (ICM)</em> method consists in testing <em>all</em> shades of gray for each pixel and updating with the configuration that allows the most important energy decrease. Even if all shades of grey are tested at each iteration, the absence of the probabilistic character (present in the simulated annealing) allows the ICM to converge much faster. On the other hand, we do not necessarily converge towards the global minimum.</p>
<p>The ICM algorithm is as follows: For each of the $n$ iterations of the algorithm, we scan all the pixels. For each pixel (noted $s$) :</p>
<ul>
<li>$\forall \lambda \in E$, calculating the energy variation if the value of $s$, $x_s^{(n-1)}$, is replaced by $\lambda$:</li>
</ul>
<p>$$ \Delta U = U_s(\lambda | V_s^{(n-1)}) - U_s(x_s^{(n-1)} | V_s^{(n-1)}) $$</p>
<ul>
<li>If the U delta is $0$, then update the pixel with a label that minimizes $\Delta U$ : $x_s^{(n)} = \lambda$</li>
</ul>
<p> </p>
<h1 id="practical-results-and-discussion">Practical results and discussion</h1>
<p>Before we could restore images, we had to deteriorate them. To do this, we used a Gaussian noise with an amplitude of $50$, simulating a Gaussian random variable and modifying the value of the pixels in the image by adding the value of the variable if this addition allows the pixel value to remain within $E = [|0, 255|]$.</p>
<p>The figure below shows the image we studied, as well as the same image scrambled with a Gaussian noise of amplitude $50$. This image is composed of a white background (pixels of value $x_s = 255$), a black square ($x_s = 0$), a dark gray star ($x_s = 70$), a gray heart ($x_s = 140$) and a light gray circle ($x_s = 210$).</p>
















<figure  id="figure-initial-image-without-noise-left-and-with-gaussian-noise-of-amplitude-50-right">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/media/restoration/figures1.png" alt="Initial image without noise (left) and with Gaussian noise of amplitude 50 (right)." loading="lazy" data-zoomable /></div>
  </div><figcaption data-pre="Figure&nbsp;" data-post=":&nbsp;" class="numbered">
      Initial image without noise (left) and with Gaussian noise of amplitude 50 (right).
    </figcaption></figure>
<p>To quantitatively evaluate the image restoration, we consider the <em>signal-to-noise ratio (SNR)</em>, which is expressed in decibels (dB) and is given by :</p>
<p>$$SNR = 10 \log \left(\dfrac{\sum_{s \in S} x_s^2}{\sum_{s \in S} (y_s-x_s)^2} \right)$$</p>
<p>where $x_s$ is the value of the $s$ pixel of the original noiseless image, and $y_s$ is the value of the $s$ pixel of the noiseless image. The greater the SNR, the less noise deteriorates the initial image. To know if the noise removal is effective, we will have to compare the values with the SNR obtained with the noisy image. The table below summarizes the SNR for a Gaussian noise of amplitude $50$.</p>
<table>
<thead>
<tr>
<th>Amplitude</th>
<th>SNR (dB)</th>
</tr>
</thead>
<tbody>
<tr>
<td>10</td>
<td>63.9516</td>
</tr>
<tr>
<td>25</td>
<td>45.2884</td>
</tr>
<tr>
<td>50</td>
<td>31.9855</td>
</tr>
<tr>
<td>100</td>
<td>20.3203</td>
</tr>
</tbody>
</table>
<p>Remember that we consider grayscale images, because the computing time is too long for color images ($E = [|0, 255|]^3$). Even for very simple grayscale images, the results obtained are far from perfect, which justifies limiting our study to this type of images.</p>
<p>There are several methods of Markov field image processing and each of these methods has its own parameters. To perform image processing, we must choose the values given to these parameters. The table below summarizes all the parameters with the default choices made, which are the choices that gave the best results when executing our algorithms.</p>
<p>The main differences in our results lie in the choice of the minimization algorithm and in the choice of the potential model.</p>
<p>We are going to apply to the scrambled image the different algorithms described above, for different parameter values. We will first study the Potts model, then the Markovian-Gaussian model.</p>
<p> </p>
<h2 id="first-series-of-tests">First series of tests</h2>
<p>At first, we consider that we know nothing about the image we need to obtain. We implement the algorithms described previously and execute them.</p>
<p> </p>
<h3 id="potts-model-1">Potts Model</h3>
<h4 id="with-simulated-annealing">With simulated annealing</h4>
<p>Given the size of the image, a scan of the noisy image shows that all shades of gray are present in the image: $E = [|0, 255|]$. We then run the simulated annealing with a Metropolis algorithm that pulls $\lambda \in E$.</p>
















<figure  id="figure-image-processed-by-simulated-annealing-and-potts-model-for-beta-in-50-100-500-from-left-to-right">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/media/restoration/figures10.png" alt="Image processed by simulated annealing and Potts model for $\beta \in \\{50, 100, 500\\}$ (from left to right)." loading="lazy" data-zoomable /></div>
  </div><figcaption data-pre="Figure&nbsp;" data-post=":&nbsp;" class="numbered">
      Image processed by simulated annealing and Potts model for $\beta \in \{50, 100, 500\}$ (from left to right).
    </figcaption></figure>
<table>
<thead>
<tr>
<th>$\beta$</th>
<th>SNR (dB)</th>
</tr>
</thead>
<tbody>
<tr>
<td>50</td>
<td>2.73104</td>
</tr>
<tr>
<td>100</td>
<td>8.48355</td>
</tr>
<tr>
<td>500</td>
<td>11.3079</td>
</tr>
<tr>
<td>10000</td>
<td>11.6187</td>
</tr>
</tbody>
</table>
<p>We see that the results improve when $\beta$ increases, with a saturation phenomenon for $\beta$ large ($\beta \approx 10^4$). However, the results are worse than the noisy image itself! The image being very noisy, the algorithm tends to replace the pixels by any value between $0$ and $255$, which does not allow to unclutter the image.</p>
<p> </p>
<h4 id="with-icm">With ICM</h4>
















<figure  id="figure-image-processed-by-icm-and-potts-model-for-1-2-and-4-iterations-from-left-to-right">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/media/restoration/figures3.png" alt="Image processed by ICM and Potts model for 1, 2 and 4 iterations (from left to right)." loading="lazy" data-zoomable /></div>
  </div><figcaption data-pre="Figure&nbsp;" data-post=":&nbsp;" class="numbered">
      Image processed by ICM and Potts model for 1, 2 and 4 iterations (from left to right).
    </figcaption></figure>
<table>
<thead>
<tr>
<th>Itérations</th>
<th>SNR (dB)</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>29.2689</td>
</tr>
<tr>
<td>2</td>
<td>27.3294</td>
</tr>
<tr>
<td>4</td>
<td>25.5964</td>
</tr>
<tr>
<td>10</td>
<td>23.1687</td>
</tr>
</tbody>
</table>
<p>The results are very good after a few iterations. Even after only one iteration, the noise has almost completely disappeared. However, the ICM tends to crop the figures, resulting in an SNR that decreases as the number of iterations increases. The SNR does not change when changing $\beta$, so $\beta$ does not seem to have any influence on the result.</p>
<p> </p>
<h3 id="gaussian-markovian-model-1">Gaussian Markovian model</h3>
<p>The Gaussian Markovian model is now being considered, and both energy minimization algorithms are being tested with and without attachment to the initial data.</p>
<p>We find that the Markovian Gaussian model blurs the images. Indeed, it tends to perform a kind of local average. Since the image is blurred by noise that takes on all values of $E = [|0, 255|]$, the averaging homogenizes the different grey areas into an average grey. Thus, even though the table below shows that the SNR is better than in the blurred image, the visual rendering and the disappearance of the noise in the white area are not good.</p>
















<figure  id="figure-image-processed-by-simulated-annealing-top-and-icm-bottom-and-markovian-gaussian-model-without-left-and-with-right-data-attachment">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/media/restoration/figures4.png" alt="Image processed by simulated annealing (top) and ICM (bottom) and Markovian Gaussian model without (left) and with (right) data attachment." loading="lazy" data-zoomable /></div>
  </div><figcaption data-pre="Figure&nbsp;" data-post=":&nbsp;" class="numbered">
      Image processed by simulated annealing (top) and ICM (bottom) and Markovian Gaussian model without (left) and with (right) data attachment.
    </figcaption></figure>
<table>
<thead>
<tr>
<th>Méthode</th>
<th>SNR (dB)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Annealing without attachment</td>
<td>35.2715</td>
</tr>
<tr>
<td>Annealing with attachment</td>
<td>38.9796</td>
</tr>
<tr>
<td>ICM without attachment</td>
<td>38.0792</td>
</tr>
<tr>
<td>ICM with attachment</td>
<td>17.2107</td>
</tr>
</tbody>
</table>
<p>This first series of tests shows that, except for the ICM with Potts model, the image restoration results are poor. For the simulated annealing with Potts, the poor results are explained by the random drawing on the $255$ shades of grey, whereas in the initial un-noiseed image, only $5$ shades are present.</p>
<p> </p>
<h2 id="second-series-of-tests">Second series of tests</h2>
<p>Configuration drawings are now made only among the shades present in the initial unclouded image: $\lambda \in E = \{0, 70, 140, 210, 255\}$.</p>
<p> </p>
<h3 id="potts-model-2">Potts model</h3>
<h4 id="with-simulated-annealing-1">With simulated annealing</h4>
















<figure  id="figure-image-processed-by-simulated-annealing-and-potts-model-for-beta-in-5-25-35-50-100-500-from-left-to-right-then-top-to-bottom">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/media/restoration/figures2.png" alt="Image processed by simulated annealing and Potts model for $\beta \in \\{5, 25, 35, 50, 100, 500\\}$ (from left to right then top to bottom)." loading="lazy" data-zoomable /></div>
  </div><figcaption data-pre="Figure&nbsp;" data-post=":&nbsp;" class="numbered">
      Image processed by simulated annealing and Potts model for $\beta \in \{5, 25, 35, 50, 100, 500\}$ (from left to right then top to bottom).
    </figcaption></figure>
<table>
<thead>
<tr>
<th>$\beta$</th>
<th>SNR (dB)</th>
</tr>
</thead>
<tbody>
<tr>
<td>5</td>
<td>3.38126</td>
</tr>
<tr>
<td>25</td>
<td>3.18447</td>
</tr>
<tr>
<td>35</td>
<td>14.8631</td>
</tr>
<tr>
<td>50</td>
<td>22.8984</td>
</tr>
<tr>
<td>100</td>
<td>23.9018</td>
</tr>
<tr>
<td>500</td>
<td>25.9764</td>
</tr>
</tbody>
</table>
<p>The results are much better than when nothing is known about the initial image, even if the SNR remains lower than that of the noisy image. We can see here the importance of the $\beta$ parameter: the larger $\beta$ is, the larger the size of the homogeneous areas increases. However, there is always a saturation phenomenon for large $\beta$. The image converges towards a state close to the initial state.</p>
<p> </p>
<h4 id="with-icm-1">With ICM</h4>
<p>The results become excellent: the image obtained is almost the initial image and the SNR is better than for the noisy image. The SNR also shows that $\beta$ still has no influence.</p>
<p> </p>
<h3 id="markovian-gaussian-model">Markovian Gaussian model</h3>
<p>The Gaussian Markovian model also gives much better results. The results are slightly better for ICM than for simulated annealing. The image obtained when the attachment is added to the initial data, including the correction of the adverse effects of the ICM at the edges, is extremely close to the initial noise-free image.</p>
















<figure  id="figure-image-processed-by-simulated-annealing-top-and-icm-bottom-and-markovian-gaussian-model-without-left-and-with-right-attached-to-the-data-and-knowing-the-shades-of-grey-present-in-the-initial-unblurred-image">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/media/restoration/figures5.png" alt="Image processed by simulated annealing (top) and ICM (bottom) and Markovian Gaussian model without (left) and with (right) attached to the data and knowing the shades of grey present in the initial unblurred image." loading="lazy" data-zoomable /></div>
  </div><figcaption data-pre="Figure&nbsp;" data-post=":&nbsp;" class="numbered">
      Image processed by simulated annealing (top) and ICM (bottom) and Markovian Gaussian model without (left) and with (right) attached to the data and knowing the shades of grey present in the initial unblurred image.
    </figcaption></figure>
<table>
<thead>
<tr>
<th>Méthode</th>
<th>SNR (dB)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Annealing without attachment</td>
<td>40.3498</td>
</tr>
<tr>
<td>Annealing with attachment</td>
<td>44.4864</td>
</tr>
<tr>
<td>ICM without attachment</td>
<td>43.9946</td>
</tr>
<tr>
<td>ICM with attachment</td>
<td>44.7768</td>
</tr>
</tbody>
</table>
<p> </p>
<h4 id="with-simulated-annealing-2">With simulated annealing</h4>
<p>The influence of $\beta$ and the saturation phenomenon are preserved: the greater the $\beta$, the better the restoration. The SNR is better than for the noisy image.</p>
<p>Modifications of the $\alpha$ parameter have been performed on the tests with data attachment, however the results are already very good for $\alpha$ small, so $\alpha$ does not seem to have a big influence. It is recalled that in theory, the larger $\alpha$ is, the greater the attachment to the initial data.</p>
















<figure  id="figure-image-processed-by-simulated-annealing-and-gaussian-markovian-model-without-top-and-with-bottom-data-attachment-for-beta-in-1-10-25-left-to-right">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/media/restoration/figures11.png" alt="Image processed by simulated annealing and Gaussian Markovian model without (top) and with (bottom) data attachment for $\beta \in \\{1, 10, 25\\}$ (left to right)." loading="lazy" data-zoomable /></div>
  </div><figcaption data-pre="Figure&nbsp;" data-post=":&nbsp;" class="numbered">
      Image processed by simulated annealing and Gaussian Markovian model without (top) and with (bottom) data attachment for $\beta \in \{1, 10, 25\}$ (left to right).
    </figcaption></figure>
<table>
<thead>
<tr>
<th>$\beta$</th>
<th>SNR (dB)</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>40.7834</td>
</tr>
<tr>
<td>10</td>
<td>40.0753</td>
</tr>
<tr>
<td>25</td>
<td>40.0668</td>
</tr>
<tr>
<td>5000</td>
<td>39.6827</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>$\beta$</th>
<th>SNR (dB)</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>32.5507</td>
</tr>
<tr>
<td>10</td>
<td>38.6730</td>
</tr>
<tr>
<td>25</td>
<td>43.5519</td>
</tr>
<tr>
<td>5000</td>
<td>43.4116</td>
</tr>
</tbody>
</table>
<p> </p>
<h4 id="with-icm-2">With ICM</h4>
<p>We make the same observations as with the simulated annealing. The best SNR among all the tests is obtained here, for $\beta = 20$.</p>
















<figure  id="figure-image-processed-by-icm-and-markovian-gaussian-model-with-data-attachment-for-beta-in-1-10-25-from-left-to-right">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/media/restoration/figures8.png" alt="Image processed by ICM and Markovian Gaussian model with data attachment for $\beta \in \\{1, 10, 25\\}$ (from left to right)." loading="lazy" data-zoomable /></div>
  </div><figcaption data-pre="Figure&nbsp;" data-post=":&nbsp;" class="numbered">
      Image processed by ICM and Markovian Gaussian model with data attachment for $\beta \in \{1, 10, 25\}$ (from left to right).
    </figcaption></figure>
<table>
<thead>
<tr>
<th>$\beta$</th>
<th>SNR (dB)</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>19.7154</td>
</tr>
<tr>
<td>10</td>
<td>39.8086</td>
</tr>
<tr>
<td>20</td>
<td>46.9805</td>
</tr>
<tr>
<td>25</td>
<td>46.474</td>
</tr>
<tr>
<td>1000</td>
<td>43.4296</td>
</tr>
<tr>
<td>5000</td>
<td>43.3621</td>
</tr>
</tbody>
</table>
<p> </p>
<h2 id="limitations-of-markovian-methods">Limitations of Markovian methods</h2>
<p>The image processed in the first series of tests had separate shapes with distant shades of grey. We are now studying an image composed of a gray scale gradient to show the limitations of Markov methods.</p>
















<figure  id="figure-initial-image-without-noise-left-and-with-gaussian-noise-of-amplitude-50-right">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/media/restoration/cercles1.png" alt="Initial image without noise (left) and with Gaussian noise of amplitude 50 (right)." loading="lazy" data-zoomable /></div>
  </div><figcaption data-pre="Figure&nbsp;" data-post=":&nbsp;" class="numbered">
      Initial image without noise (left) and with Gaussian noise of amplitude 50 (right).
    </figcaption></figure>
<p>Simulated annealing methods and ICM with $\beta$ large, Gaussian Markovian model with data attachment and knowledge of the initial grades are applied to the image as these are the choices that have given the best results so far. The results are shown in below.</p>
<p>It can be seen that the simulated annealing with Potts&rsquo; model gives a result similar to the one of the image with the different shapes for $\beta = 25$. When $\beta$ is increased, the result does not improve and remains close to that.</p>
<p>ICM with Potts tends to deteriorate the edges as seen in the first series of tests. However, as the shades of grey are close together, this causes some of them to disappear.</p>
<p>The Gaussian Markovian model gives very good results whatever the potential. The SNR obtained is double that of the noisy image, which is even better than the results for the image with the different shapes.</p>
<p>To conclude this study and to show the limits of Markovian methods on close shades, we tested the different algorithms on a photo with the $255$ shades of grey. The method giving the best SNR is the Markovian Gaussian model with data attachment, although this model results in blurring of the image.</p>
















<figure  id="figure-image-processed-by-simulated-annealing-left-and-icm-right-for-the-potts-model-top-and-the-markovian-gaussian-model-with-data-attachment-bottom-for-beta-large">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/media/restoration/cercles2.png" alt="Image processed by simulated annealing (left) and ICM (right) for the Potts model (top) and the Markovian-Gaussian model with data attachment (bottom) for $\beta$ large." loading="lazy" data-zoomable /></div>
  </div><figcaption data-pre="Figure&nbsp;" data-post=":&nbsp;" class="numbered">
      Image processed by simulated annealing (left) and ICM (right) for the Potts model (top) and the Markovian-Gaussian model with data attachment (bottom) for $\beta$ large.
    </figcaption></figure>
















<figure  id="figure-initial-noise-free-image-left-with-gaussian-noise-of-amplitude-50-middle-and-image-processed-by-markovian-gaussian-model-with-data-attachment-right-for-beta-large">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/media/restoration/resultatslenna.png" alt="Initial noise-free image (left), with Gaussian noise of amplitude $50$ (middle) and image processed by Markovian Gaussian model with data attachment (right) for $\beta$ large." loading="lazy" data-zoomable /></div>
  </div><figcaption data-pre="Figure&nbsp;" data-post=":&nbsp;" class="numbered">
      Initial noise-free image (left), with Gaussian noise of amplitude $50$ (middle) and image processed by Markovian Gaussian model with data attachment (right) for $\beta$ large.
    </figcaption></figure>
<p> </p>
<h1 id="conclusion">Conclusion</h1>
<p>Denoising an image is an important step in many advanced fields such as medicine or cartography. Our project presents a method for denoising black and white images based on Markov field theory and Ising and Potts physical models. The theoretical study of the Markov model highlights the need to choose the right minimization approach, as well as the sampling algorithm.</p>
<p>We were confronted with the problem of calibrating different parameters. The results show the efficiency of the ICM algorithm with the potentials from the Gaussian Markovian model, which, compared to other models, presents a better restitution of the deteriorated image. The better the information is known about the original image, the better the restoration.</p>
<p> </p>
<!---

&nbsp;

# Présentation du projet

L'acquisition d'une image numérique est le plus souvent accompagnée de l'apparition de bruit, souvent dû à une imperfection au niveau de la détection, de la transmission ou de la compression du signal, ou encore à des défauts inhérents à l'environnement comme la présence d'éclairage insuffisant ou trop prononcé. La suppression de ce bruit est même un enjeu vital dans plusieurs domaines, notamment l'imagerie médicale, et la recherche d'un algorithme efficace de débruitage d'image demeure un défi persistant, à la croisée de plusieurs domaines scientifiques : analyse fonctionelle, probabilités, statistiques et sciences physiques.

Dans cette étude, nous implémentons différents algorithmes de restitution d'une image contenant des motifs simples, en niveaux de gris, bruitée selon un bruit gaussien. Pour cela, nous adoptons une description probabiliste de l'image, considérant ses pixels comme des variables aléatoires $X_i$, d'énergie $U(X_i)$ qui dépend de son voisinage. Cette approche permet d'envisager l'image comme un champ de Markov.

&nbsp;

# Implémentation numérique des champs de Markov

Nous formulons à présent les méthodes probabilistes que nous avons implémentées numériquement pour les appliquer au traitement d'images.

Dans le cadre de notre étude, nous considérerons des images rectangulaires en niveau de gris (de 0 à 255), de longueur $w$ et de hauteur $h$. Chaque pixel de l'image est représenté par ses coordonnées $(i,j)$ et une valeur correspondant au niveau de gris du pixel, cette valeur appartenant à $E = [|0, 255|]$. L'image totale peut donc être représentée par un tableau de valeurs de E, de dimension $w \times h$.

Pour chaque pixel, on peut définir un système de cliques tel qu'expliqué en *(2.1.2)*. Dans nos codes informatiques, la présence d'une variable $c$ qui prendra la valeur $4$ ou $8$ permettra de choisir si l'on considère des voisinages 4 ou 8-connexe, et on considèrera des cliques d'ordre 2.

L'implémentation des algorithmes de traitement d'image comporte trois phases principales :

- le choix d'un champ de Markov adapté
- le tirage d'une configuration selon le champ de Markov choisi
- l'implémentation de l'algorithme qui converge vers une image correcte après un certain nombre de tirages.

Nous décrivons ces trois phases de façon théorique, puis nous analyserons les résultats obtenus avec les différentes méthodes.

&nbsp;

## Champs de Markov en traitement d'image

Nous présentons ici les champs de Markov les plus utilisés en traitement d'image ainsi que quelques variantes donnant de meilleurs résultats.

&nbsp;

### Modèle d'Ising :

Comme nous l'avons indiqué en \textbf{(2.2)}, ce modèle n'est applicable qu'à une image comprenant 2 niveaux de gris. Par une transformation affine, on peut associer à ces 2 valeurs les valeurs de l'ensemble $E = \{-1, 1\}$. On rappelle l'énergie de ce modèle :

$$U(x) = - \sum_{c=(s,t) \in C} \beta x_s x_t - \sum_{s \in S} B x_s$$

&nbsp;

### Modèle de Potts :

Il s'agit de la généralisation du modèle d'Ising, adaptée à un ensemble $E$ de cardinal N, comme $E = [|0, 255|]$. La différence principale avec le modèle d'Ising est que seuls les potentiels liés aux cliques d'ordre 2 sont définis. Il n'y a pas de terme d'énergie lié aux cliques d'ordre 1, correspondant à un champ magnétique externe. L'énergie de ce modèle est :

$$U(x) = \ \beta \sum_{c=(s,t) \in C} (\textbf{1}_{\{x_s \neq x_t\}} - \textbf{1}_{\{x_s = x_t\}})$$

Un tel modèle tend à créer des zones homogènes de taille d'autant plus grande que $\beta$ est grand.

&nbsp;

### Modèle markovien gaussien :

Ce modèle n'est utilisable que pour les images en niveaux de gris, ce qui est parfaitement adapté à notre étude. On considère, ici encore, des voisinages 4 ou 8-connexes et seulement des cliques d'ordre 2. L'énergie de ce modèle est :

$$U(x) = \beta \sum_{c=(s,t) \in C} (x_s-x_t)^2 + \alpha \sum_{s \in S} (x_s-\mu_s)^2$$

Pour $\beta > 0$, le premier terme quadratique favorise les faibles différences de niveaux de gris, puisqu'il s'agit de minimiser une énergie qui augmente de façon quadratique avec l'écart en niveaux de gris. Le second terme fait intervenir un terme $\mu_s$ qui correspond à une image de référence. Si l'on connaît une approximation de l'image que l'on veut obtenir, ou si l'on veut rester proche de l'image initiale, ce terme permet à l'image solution $x$ de ne pas s'éloigner de l'image de référence $\mu$.

&nbsp;

## Tirage d'une configuration selon le champ de Markov

Après le choix d'un champ de Markov, il faut procéder à la minimisation de son énergie totale. On procède par tirage de configurations. L'idée générale est de tirer pour chaque pixel une valeur aléatoire et de lui attribuer cette valeur si elle permet la diminution de l'énergie totale.

Les algorithmes les plus utilisés pour réaliser ces tirages, l'échantillonneur de Gibbs et l'algorithme de Metropolis, fonctionnent de façon similaire. On procède à $n$ itérations, où l'on choisit aléatoirement un pixel $s$ puis on associe à $s$ une expérience aléatoire en fonction de l'image à l'itération $n-1$. On met à jour ou non $s$ selon le résultat de l'expérience aléatoire.

Comme il faut balayer l'ensemble des pixels $s$ un grand nombre de fois, on balaye généralement l'ensemble des pixels ligne par ligne et de gauche à droite sans réaliser de tirage aléatoire, pour être sûr que tous les pixels ont été soumis à des mises à jour. L'algorithme cesse après un grand nombre $n$ d'itérations, ou lorsqu'il y a peu de changements de pixels pour une itération.

Pour ces deux algorithmes, on parle d'algorithme de relaxation probabiliste : relaxation car l'algorithme réalise des mises à jour successives des différents pixels, et probabiliste car l'algorithme simule des tirages aléatoires.

Voici le contenu des algorithmes.

&nbsp;

### L'échantillonneur de Gibbs :

Pour chacune des $n$ itérations de l'algorithme, on balaye l'ensemble des pixels. Pour chaque pixel (noté $s$) :

- Calcul de la probabilité locale, connaissant la configuration des voisins $V_s$ pour l'image à l'itération $n-1$ :

$$ \mathbb{P} (X_s = x_s | V_s) = \dfrac{\exp (-U_s(x_s | V_s))}{\sum_{a_s \in A_s}{\exp (-U_s(a_s | V_s))}}$$

- Mise à jour du site par tirage aléatoire selon la loi $\mathbb{P}(X_s = x_s | V_s)$

&nbsp;

### L'algorithme de Metropolis :

Pour chacune des $n$ itérations de l'algorithme, on balaye l'ensemble des pixels. Pour chaque pixel (noté $s$) :

- Tirage aléatoire de $\lambda$ dans $E$ selon une loi uniforme sur $E$:
- Calcul de la variation d'énergie si la valeur de $s$, $x_s^{(n-1)}$, est remplacée par $\lambda$ :
    $$ \Delta U = U_s(\lambda | V_s^{(n-1)}) - U_s(x_s^{(n-1)} | V_s^{(n-1)}) $$
- Si $ \Delta U \leq 0$, alors on met à jour le pixel : $x_s^{(n)} = \lambda$
- Sinon, on met à jour selon la probabilité de succès $p = \exp (- \Delta U)$

&nbsp;

## Implémentation de l'algorithme de restauration d'image

Après avoir implémenté un algorithme de tirage de configuration, il faut implémenter un algorithme convergeant vers une image solution du problème de minimisation de l'énergie totale. Deux algorithmes sont principalement utilisés dans le cadre du traitement d'image par champs de Markov.

&nbsp;

### Le recuit simulé :

Le recuit simulé est une méthode classique de minimisation d'énergie fréquemment utilisée en physique. En traitement d'image, l'algorithme consiste en $n$ itérations au cours desquelles on réalise des tirages de configuration tels que décrits en *(2.3.2)*. Cependant, ces tirages ne dépendent plus que de l'énergie de configuration, mais aussi d'une quantité $T^{(n)}$ qui mesure le degré d'aléatoire introduit dans ces tirages, qu'on nomme température et qui décroît à chaque itération. Partant d'une température $T^{(0)}$ assez grande et de l'image à traiter, l'algorithme est le suivant :

Pour chaque itération $n$,

- Tirage d'une configuration en remplaçant les énergies $U(x)$ par les quantités $U(x) / T^{(n)}$ pour les tirages de mise à jour des pixels
- Diminution de la température selon une décroissance logarithmique : $T^{(n)} > \dfrac{c}{\log(2+n)}$

La décroissance logarithmique est nécessaire pour obtenir la convergence en probabilité de l'algorithme vers l'image qui minimise l'énergie. En pratique, pour des images complexes ou grandes, cette décroissance est trop lente et on préfère utiliser une décroissance linéaire ou quadratique, ce qui peut provoquer une convergence vers un minimum seulement local de l'énergie. Cependant, la taille ($200 \times 200$ pixels) et la simplicité des images que nous traitons nous autorise à utiliser cette décroissance logarithmique. On a observé de légères différences entre la décroissance logarithmique et la décroissance linéaire, ce qui est cohérent avec les notions de minimum local et minimum global de l'énergie.

&nbsp;

### Les modes conditionnels itérés :

La méthode *Iterated Conditional Mode (ICM)* consiste à tester *toutes* les nuances de gris pour chaque pixel et à mettre à jour avec la configuration qui permet la diminution d'énergie la plus importante. Même si l'on teste à chaque itération toutes les nuances de gris, l'absence du caractère probabiliste (présent dans le recuit simulé) permet à l'ICM de converger bien plus rapidement. En revanche, on ne converge pas forcément vers le minimum global.

L'algorithme ICM est le suivant : Pour chacune des $n$ itérations de l'algorithme, on balaye l'ensemble des pixels. Pour chaque pixel (noté $s$) :

- $\forall \lambda \in E$, calcul de la variation d'énergie si la valeur de $s$, $x_s^{(n-1)}$, est remplacée par $\lambda$ :

$$ \Delta U = U_s(\lambda | V_s^{(n-1)}) - U_s(x_s^{(n-1)} | V_s^{(n-1)}) $$

- Si $ \Delta U \leq 0$, alors mise à jour le pixel avec $\lambda$ qui minimise $ \Delta U$ : $x_s^{(n)} = \lambda$

&nbsp;

# Résultats pratiques et discussion

Avant de pouvoir restaurer des images, il nous a fallu les détériorer. Pour cela, nous avons utilisé un bruit gaussien d'amplitude 50. Il s'agit de simuler une variable aléatoire gaussienne et de modifier la valeur des pixels de l'image en ajoutant la valeur de la variable si cet ajout permet à la valeur du pixel de rester dans $E = [|0, 255|]$.

La figure ci-dessous montre l'image que nous avons étudiée, ainsi que la même image brouillée avec un bruit gaussien d'amplitude 50. Cette image est composée d'un fond blanc (pixels de valeur $x_s = 255$), d'un carré noir ($x_s = 0$), d'une étoile gris foncé ($x_s = 70$), d'un coeur gris ($x_s = 140$) et d'un rond gris clair ($x_s = 210$).

















<figure  id="figure-image-initiale-sans-bruit-à-gauche-et-avec-bruit-gaussien-damplitude-50-à-droite">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/media/restoration/figures1.png" alt="Image initiale sans bruit (à gauche) et avec bruit gaussien d’amplitude 50 (à droite)." loading="lazy" data-zoomable /></div>
  </div><figcaption data-pre="Figure&nbsp;" data-post=":&nbsp;" class="numbered">
      Image initiale sans bruit (à gauche) et avec bruit gaussien d’amplitude 50 (à droite).
    </figcaption></figure>

Pour évaluer quantitativement la restauration d'image, nous considérons le rapport signal sur bruit *(signal-to-noise ratio, SNR)*, qui s'exprime en décibels (dB) et est donné par :

$$SNR = 10 \log \left(\dfrac{\sum_{s \in S} x_s^2}{\sum_{s \in S} (y_s-x_s)^2} \right)$$

où $x_s$ est la valeur du pixel $s$ de l'image initiale non bruitée, et $y_s$ de même pour l'image débruitée. Plus SNR est grand, moins le bruit détériore l'image initiale. Pour savoir si le débruitage est efficace, il nous faudra comparer les valeurs avec le SNR obtenu avec l'image bruitée. Le tableau 1 rescense notamment le SNR pour un bruit gaussien d'amplitude 50.

| Amplitude | SNR (dB) |
|-----------|----------|
| 10        | 63.9516  |
| 25        | 45.2884  |
| 50        | 31.9855  |
| 100       | 20.3203  |

On rappelle qu'on considère des images en niveaux de gris, car le temps de calcul est trop important pour des images en couleur ($E = [|0, 255|]^3$). Même pour des images très simples en niveaux de gris, les résultats obtenus sont loin d'être parfaits, ce qui justifie de limiter notre étude à ce type d'images.

Comme expliqué en *(2.3}*, il existe plusieurs méthodes de traitement d'image par champs de Markov et chacune de ces méthodes possède ses propres paramètres. Pour réaliser un traitement d'image, nous devons choisir les valeurs données à ces paramètres. Le tableau ci-dessous rescense l'ensemble des paramètres avec les choix par défaut effectués, qui sont les choix qui ont donné les meilleurs résultats lors de l'exécution de nos algorithmes.

Les principales différences dans nos résultats résident dans le choix de l'algorithme de minimisation et dans le choix du modèle de potentiel.

On va appliquer à l'image brouillée les différents algorithmes décrits précédemment, pour différentes valeurs des paramètres. On va d'abord étudier le modèle de Potts, puis le modèle markovien gaussien.

&nbsp;

## Première série d'essais

On considère dans un premier temps que l'on ne connaît rien de l'image que l'on doit obtenir. On implémente les algorithmes tels que décrits en *(2.3)* et on les exécute.

&nbsp;

### Le modèle de Potts

#### Avec recuit simulé :

Étant donné la taille de l'image, un balayage de l'image bruitée montre que toutes les nuances de gris sont présentes sur l'image : $E = [|0, 255|]$. On exécute alors le recuit simulé avec un algorithme de Metropolis qui tire $\lambda \in E$.

















<figure  id="figure-image-traitée-par-recuit-simulé-et-modèle-de-potts-pour-beta-in-50-100-500-de-gauche-à-droite">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/media/restoration/figures10.png" alt="Image traitée par recuit simulé et modèle de Potts pour $\beta \in \\{50, 100, 500\\}$ (de gauche à droite)." loading="lazy" data-zoomable /></div>
  </div><figcaption data-pre="Figure&nbsp;" data-post=":&nbsp;" class="numbered">
      Image traitée par recuit simulé et modèle de Potts pour $\beta \in \{50, 100, 500\}$ (de gauche à droite).
    </figcaption></figure>

| $\beta$   | SNR (dB) |
|-----------|----------|
| 50        | 2.73104  |
| 100       | 8.48355  |
| 500       | 11.3079  |
| 10000     | 11.6187  |

On constate que les résultats s'améliorent lorsque $\beta$ augmente, avec un phénomène de saturation pour $\beta$ grand ($\beta \approx 10^4$). Cependant, les résultats sont pires que l'image bruitée elle-même ! L'image étant très bruitée, l'algorithme tend à remplacer les pixels par n'importe quelle valeur entre 0 et 255, ce qui ne permet pas de débruiter l'image.

&nbsp;

#### Avec ICM :

















<figure  id="figure-image-traitée-par-icm-et-modèle-de-potts-pour-1-2-et-4-itérations-de-gauche-à-droite">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/media/restoration/figures3.png" alt="Image traitée par ICM et modèle de Potts pour 1, 2 et 4 itérations (de gauche à droite)." loading="lazy" data-zoomable /></div>
  </div><figcaption data-pre="Figure&nbsp;" data-post=":&nbsp;" class="numbered">
      Image traitée par ICM et modèle de Potts pour 1, 2 et 4 itérations (de gauche à droite).
    </figcaption></figure>

| Itérations | SNR (dB) |
|------------|----------|
| 1          | 29.2689  |
| 2          | 27.3294  |
| 4          | 25.5964  |
| 10         | 23.1687  |

Les résultats sont très bons après quelques itérations. Même après une seule itération, le bruit a presque entièrement disparu. Toutefois, l'ICM tend à rogner les figures, d'où un SNR qui diminue lorsque le nombre d'itérations augmente. Le SNR ne varie pas lorsqu'on change $\beta$, donc  $\beta$ ne semble pas avoir d'influence sur le résultat.

&nbsp;

### Le modèle markovien gaussien

On considère désormais le modèle markovien gaussien, et on teste les deux algorithmes de minimisation d'énergie avec et sans attache aux données initiales.

On constate que le modèle markovien gaussien floute les images. En effet, il tend à effectuer une sorte de moyenne locale. Or, l'image étant brouillée par un bruit qui prend toutes les valeurs de $E = [|0, 255|]$, le moyennage homogénéise les différentes zones de gris en un gris moyen. Ainsi, même si le tableau 5 montre que le SNR est meilleur que sur l'image brouillée, le rendu visuel et la disparition du bruit sur la zone blanche ne sont pas bons.

















<figure  id="figure-image-traitée-par-recuit-simulé-en-haut-et-icm-en-bas-et-modèle-markovien-gaussien-sans-à-gauche-et-avec-à-droite-attache-aux-données">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/media/restoration/figures4.png" alt="Image traitée par recuit simulé (en haut) et ICM (en bas) et modèle markovien gaussien sans (à gauche) et avec (à droite) attache aux données." loading="lazy" data-zoomable /></div>
  </div><figcaption data-pre="Figure&nbsp;" data-post=":&nbsp;" class="numbered">
      Image traitée par recuit simulé (en haut) et ICM (en bas) et modèle markovien gaussien sans (à gauche) et avec (à droite) attache aux données.
    </figcaption></figure>

| Méthode             | SNR (dB) |
|---------------------|----------|
| Recuit sans attache | 35.2715  |
| Recuit avec attache | 38.9796  |
| ICM sans attache    | 38.0792  |
| ICM avec attache    | 17.2107  |

Cette première série d'essais montre que, mis à part pour l'ICM avec modèle de Potts, les résultats de restauration d'image sont mauvais. Pour le recuit simulé avec Potts, les mauvais résultats s'expliquent par le tirage aléatoire sur les 255 nuances de gris, alors que dans l'image initiale non bruitée, seules 5 nuances sont présentes.

&nbsp;

## Seconde série d'essais

On réalise désormais les tirages de configuration seulement parmi les nuances présentes sur l'image initiale non bruitée : $\lambda \in E = \\{0, 70, 140, 210, 255\\}$.

&nbsp;

### Le modèle de Potts

#### Avec recuit simulé :

















<figure  id="figure-image-traitée-par-recuit-simulé-et-modèle-de-potts-pour-beta-in-5-25-35-50-100-500-de-gauche-à-droite-puis-de-haut-en-bas">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/media/restoration/figures2.png" alt="Image traitée par recuit simulé et modèle de Potts pour $\beta \in \\{5, 25, 35, 50, 100, 500\\}$ (de gauche à droite puis de haut en bas)." loading="lazy" data-zoomable /></div>
  </div><figcaption data-pre="Figure&nbsp;" data-post=":&nbsp;" class="numbered">
      Image traitée par recuit simulé et modèle de Potts pour $\beta \in \{5, 25, 35, 50, 100, 500\}$ (de gauche à droite puis de haut en bas).
    </figcaption></figure>

| $\beta$   | SNR (dB) |
|-----------|----------|
| 5         | 3.38126  |
| 25        | 3.18447  |
| 35        | 14.8631  |
| 50        | 22.8984  |
| 100       | 23.9018  |
| 500       | 25.9764  |

Les résultats sont bien meilleurs que lorsqu'on ne connaît rien de l'image initiale, même si le SNR reste inférieur à celui de l'image bruitée. On constate ici l'importance du paramètre $\beta$ : plus $\beta$ est grand, plus la taille des zones homogènes augmente. On a cependant toujours un phénomène de saturation pour $\beta$ grand. L'image converge vers un état proche de l'état initial.

&nbsp;

#### Avec ICM :

Les résultats deviennent excellents : l'image obtenue est quasiment l'image initiale et le SNR est meilleur que pour l'image bruitée. Le SNR montre aussi que $\beta$ n'a toujours pas d'influence.

&nbsp;

### Le modèle markovien gaussien

Le modèle markovien gaussien donne aussi de biens meilleurs résultats. Les résultats sont légèrement meilleurs pour l'ICM que pour le recuit simulé. L'image obtenue lorsqu'on ajoute l'attache aux données initiales, qui permet notamment de corriger les effets néfastes de l'ICM sur les bords, est extrêmement proche de l'image initiale non bruitée.

















<figure  id="figure-image-traitée-par-recuit-simulé-en-haut-et-icm-en-bas-et-modèle-markovien-gaussien-sans-à-gauche-et-avec-à-droite-attache-aux-données-et-connaissant-les-nuances-de-gris-présentes-dans-limage-initiale-non-brouillée">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/media/restoration/figures5.png" alt="Image traitée par recuit simulé (en haut) et ICM (en bas) et modèle markovien gaussien sans (à gauche) et avec (à droite) attache aux données et connaissant les nuances de gris présentes dans l’image initiale non brouillée." loading="lazy" data-zoomable /></div>
  </div><figcaption data-pre="Figure&nbsp;" data-post=":&nbsp;" class="numbered">
      Image traitée par recuit simulé (en haut) et ICM (en bas) et modèle markovien gaussien sans (à gauche) et avec (à droite) attache aux données et connaissant les nuances de gris présentes dans l’image initiale non brouillée.
    </figcaption></figure>

| Méthode             | SNR (dB) |
|---------------------|----------|
| Recuit sans attache | 40.3498  |
| Recuit avec attache | 44.4864  |
| ICM sans attache    | 43.9946  |
| ICM avec attache    | 44.7768  |

&nbsp;

#### Avec recuit simulé :

L'influence de $\beta$ et le phénomène de saturation sont conservés : plus $\beta$ est grand, meilleure est la restauration. Le SNR est meilleur que pour l'image bruitée.

Des modifications du paramètre $\alpha$ ont été réalisées sur les tests avec attache aux données, cependant les résultats étant déjà très bons pour $\alpha$ petit, $\alpha$ ne semble pas avoir une grande influence. On rappelle qu'en théorie, plus $\alpha$ est grand, plus l'attache aux données initiales est importante.

















<figure  id="figure-image-traitée-par-recuit-simulé-et-modèle-markovien-gaussien-sans-en-haut-et-avec-en-bas-attache-aux-données-pour-beta-in-1-10-25-de-gauche-à-droite">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/media/restoration/figures11.png" alt="Image traitée par recuit simulé et modèle markovien gaussien sans (en haut) et avec (en bas) attache aux données pour $\beta \in \\{1, 10, 25\\}$ (de gauche à droite)." loading="lazy" data-zoomable /></div>
  </div><figcaption data-pre="Figure&nbsp;" data-post=":&nbsp;" class="numbered">
      Image traitée par recuit simulé et modèle markovien gaussien sans (en haut) et avec (en bas) attache aux données pour $\beta \in \{1, 10, 25\}$ (de gauche à droite).
    </figcaption></figure>

| $\beta$   | SNR (dB) |
|-----------|----------|
| 1         | 40.7834  |
| 10        | 40.0753  |
| 25        | 40.0668  |
| 5000      | 39.6827  |

| $\beta$   | SNR (dB) |
|-----------|----------|
| 1         | 32.5507  |
| 10        | 38.6730  |
| 25        | 43.5519  |
| 5000      | 43.4116  |

&nbsp;

#### Avec ICM :

On réalise les mêmes constats qu'avec le recuit simulé. Le meilleur SNR parmi tous les essais est obtenu ici, pour $\beta = 20$ (tableau 10).

















<figure  id="figure-image-traitée-par-icm-et-modèle-markovien-gaussien-avec-attache-aux-données-pour-beta-in-1-10-25-de-gauche-à-droite">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/media/restoration/figures8.png" alt="Image traitée par ICM et modèle markovien gaussien avec attache aux données pour $\beta \in \\{1, 10, 25\\}$ (de gauche à droite)." loading="lazy" data-zoomable /></div>
  </div><figcaption data-pre="Figure&nbsp;" data-post=":&nbsp;" class="numbered">
      Image traitée par ICM et modèle markovien gaussien avec attache aux données pour $\beta \in \{1, 10, 25\}$ (de gauche à droite).
    </figcaption></figure>

| $\beta$   | SNR (dB) |
|-----------|----------|
| 1         | 19.7154  |
| 10        | 39.8086  |
| 20        | 46.9805  |
| 25        | 46.474   |
| 1000      | 43.4296  |
| 5000      | 43.3621  |

&nbsp;

## Limites des méthodes markoviennes

L'image traitée dans la première série de tests comportait des formes séparées avec des nuances de gris éloignées. Nous étudions désormais une image composée d'un dégradé de gris pour montrer les limites des méthodes markoviennes.

















<figure  id="figure-image-initiale-sans-bruit-à-gauche-et-avec-bruit-gaussien-damplitude-50-à-droite">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/media/restoration/cercles1.png" alt="Image initiale sans bruit (à gauche) et avec bruit gaussien d’amplitude 50 (à droite)." loading="lazy" data-zoomable /></div>
  </div><figcaption data-pre="Figure&nbsp;" data-post=":&nbsp;" class="numbered">
      Image initiale sans bruit (à gauche) et avec bruit gaussien d’amplitude 50 (à droite).
    </figcaption></figure>

On applique à l'image les méthodes de recuit simulé et l'ICM avec $\beta$ grand, modèle markovien gaussien avec attache aux données et connaissance des nuances initiales car ce sont les choix qui ont donné les meilleurs résultats jusqu'à présent. Les résultats sont représentés en *figure 17*.

On constate que le recuit simulé avec modèle de Potts donne un résultat analogue à celui de la *figure 12* pour $\beta = 25$. Lorsqu'on augmente $\beta$, le résultat ne s'améliore pas et reste proche de celui en *figure 17*.

L'ICM avec Potts tend à détériorer les bords comme constaté dans la première série de tests. Toutefois, les nuances de gris étant proches, cela provoque la disparition de certaines.

Le modèle markovien gaussien donne de très bons résultats quel que soit le potentiel. Le SNR obtenu est le double de celui de l'image bruitée en *figure 16*, ce qui est même meilleur que pour les résultats de la *figure 15*.

Pour conclure cette étude et montrer les limites des méthodes markoviennes sur des nuances proches, nous avons testé les différents algorithmes sur une photo avec les 255 nuances de gris. La méthode donnant le meilleur SNR est le modèle markovien gaussien avec attache aux données, bien que ce modèle ait pour conséquence de flouter l'image.

















<figure  id="figure-image-traitée-par-recuit-simulé-à-gauche-et-icm-à-droite-pour-le-modèle-de-potts-en-haut-et-le-modèle-markovien-gaussien-avec-attache-aux-données-en-bas-pour-beta-grand">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/media/restoration/cercles2.png" alt="Image traitée par recuit simulé (à gauche) et ICM (à droite) pour le modèle de Potts (en haut) et le modèle markovien gaussien avec attache aux données (en bas) pour $\beta$ grand." loading="lazy" data-zoomable /></div>
  </div><figcaption data-pre="Figure&nbsp;" data-post=":&nbsp;" class="numbered">
      Image traitée par recuit simulé (à gauche) et ICM (à droite) pour le modèle de Potts (en haut) et le modèle markovien gaussien avec attache aux données (en bas) pour $\beta$ grand.
    </figcaption></figure>

















<figure  id="figure-image-initiale-sans-bruit-à-gauche-avec-bruit-gaussien-damplitude-50-au-milieu-et-image-traitée-par-modèle-markovien-gaussien-avec-attache-aux-données-à-droite-pour-beta-grand">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/media/restoration/resultatslenna.png" alt="Image initiale sans bruit (à gauche), avec bruit gaussien d’amplitude 50 (au milieu) et image traitée par modèle markovien gaussien avec attache aux données (à droite) pour $\beta$ grand." loading="lazy" data-zoomable /></div>
  </div><figcaption data-pre="Figure&nbsp;" data-post=":&nbsp;" class="numbered">
      Image initiale sans bruit (à gauche), avec bruit gaussien d’amplitude 50 (au milieu) et image traitée par modèle markovien gaussien avec attache aux données (à droite) pour $\beta$ grand.
    </figcaption></figure>

&nbsp;

# Conclusion

Débruiter une image est une étape importante dans plusieurs domaines avancés comme la médecine ou la cartographie. Notre projet présente une méthode de débruitage d'images en noir et blanc reposant sur la théorie des champs de Markov et sur les modèles physiques d'Ising et de Potts. L'étude théorique du modèle markovien met en avant la nécessité de choisir la bonne approche de minimisation, ainsi que de l'algorithme d'échantillonnage.

Nous avons été confrontés au problème de calibrage de différents paramètres. Les résultats montrent l'efficacité de l'algorithme ICM avec les potentiels issus du modèle markovien gaussien, qui, par comparaison aux autres modèles, présente une meilleure restitution de l'image détériorée. La restauration est d'autant meilleure que l'on connaît des informations sur l'image initiale.

&nbsp;

--->

    </div>

    







<div class="share-box">
  <ul class="share">
    
  </ul>
</div>











  
  
    



  
  
  
    
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <a href="https://michaelkarpe.github.io/"><img class="avatar mr-3 avatar-circle" src="/authors/admin/avatar_hu66194438bc6e14d260870deead871271_609448_270x270_fill_q75_lanczos_center.jpg" alt="Michaël Karpe"></a>
    

    <div class="media-body">
      <h5 class="card-title"><a href="https://michaelkarpe.github.io/">Michaël Karpe</a></h5>
      <h6 class="card-subtitle">Quantitative Developer</h6>
      <p class="card-text">Quantitative Developer at Next Gate Tech. MEng in Industrial Engineering &amp; Operations Research, FinTech Concentration at University of California, Berkeley. Diplôme d&rsquo;Ingénieur (MSc) in Applied Mathematics &amp; Computer Science, Machine Learning &amp; Computer Vision Concentration at Ecole des Ponts ParisTech, France.</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.linkedin.com/in/michaelkarpe/" target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/MichaelKarpe" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://scholar.google.com/citations?user=2yQ3TvgAAAAJ" target="_blank" rel="noopener">
        <i class="ai ai-google-scholar"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.kaggle.com/mika30" target="_blank" rel="noopener">
        <i class="fab fa-kaggle"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>


  
    




  
    




  
    




  
















  </div>
</article>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  












  

  

  

  
  






  
  <p class="powered-by copyright-license-text">
    © Michaël Karpe 2022. All rights reserved.
  </p>
  




  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a> — the free, <a href="https://github.com/wowchemy/wowchemy-hugo-themes" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

  


<script src="/js/vendor-bundle.min.d26509351aa0ff874abbee824e982e9b.js"></script>




  

  
  

  













  
  <script id="search-hit-fuse-template" type="text/x-template">
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script>
  
    <script src="https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
  












  
  
  
  
  
  
  







<script id="page-data" type="application/json">{"use_headroom":true}</script>



  <script src="/js/wowchemy-headroom.c251366b4128fd5e6b046d4c97a62a51.js" type="module"></script>








  
  


<script src="/en/js/wowchemy.min.54dd6e4d8f2e4b1d098381b57f18dd83.js"></script>







  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        
        <pre><code></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>


  <script src="/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js" type="module"></script>
















</body>
</html>
