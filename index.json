
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"Michaël Karpe is Machine Learning Scientist at Next Gate Tech, a Luxembourg-based FinTech scaleup providing Data Management as a Service for the financial industry. He has 4+ years of experience in Machine Learning Science \u0026amp; Engineering and Quantitative Research \u0026amp; Development, working with global financial services companies and scaleups.\nMichaël Karpe studied Applied Mathematics \u0026amp; Computer Science, including Machine Learning, Computer Vision, Operations Research, and Financial Engineering. He received a Master of Engineering from the University of California, Berkeley, and a Master of Science from the École des Ponts ParisTech.\nMichaël Karpe is passionate about real-world applications of Machine Learning, having won a Kaggle Analytics competition in 2020. He is also a fervent public speaker and debater, having reached the semifinals of the French Debating Association tournament in 2018.\n","date":1591747200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1591747200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Michaël Karpe is Machine Learning Scientist at Next Gate Tech, a Luxembourg-based FinTech scaleup providing Data Management as a Service for the financial industry. He has 4+ years of experience in Machine Learning Science \u0026 Engineering and Quantitative Research \u0026 Development, working with global financial services companies and scaleups.","tags":null,"title":"Michaël Karpe","type":"authors"},{"authors":["Michaël Karpe","Jin Fang","Zhongyao Ma","Chen Wang"],"categories":null,"content":"","date":1591747200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591747200,"objectID":"291aaa580e329654ed5a02a0707d853f","permalink":"https://michaelkarpe.github.io/publication/karpe2020multiagent/","publishdate":"2020-06-10T00:00:00Z","relpermalink":"/publication/karpe2020multiagent/","section":"publication","summary":"We propose a model-free approach by training Reinforcement Learning (RL) agents in a realistic market simulation environment.","tags":null,"title":"Multi-Agent Reinforcement Learning in a Realistic Limit Order Book Market Simulation","type":"publication"},{"authors":["Michaël Karpe"],"categories":null,"content":"","date":1591660800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591660800,"objectID":"c3fbe13e75d7fa0b6e646803f980fe1e","permalink":"https://michaelkarpe.github.io/publication/karpe2020overall/","publishdate":"2020-06-09T00:00:00Z","relpermalink":"/publication/karpe2020overall/","section":"publication","summary":"We summarize the fundamental issues at stake in algorithmic trading, and the progress made in this field over the last twenty years.","tags":null,"title":"An overall view of key problems in algorithmic trading and recent progress","type":"publication"},{"authors":["Michaël Karpe"],"categories":null,"content":" How long does it take to get from the Bronx to Staten Island in an NYC yellow cab?\nIn the “NYC Taxi Trip Duration Prediction” challenge of my UC Berkeley “Applications in Data Analysis” course, I built a machine learning model to predict the duration of an NYC taxi trip as soon as you enter the taxi! As the winning model of the challenge, this model predicts the duration of such a trip with a root mean square error of less than 4.5 minutes.\nIf you are interested in machine learning and want to know how to build a powerful model on a simple regression problem (or if you just like machine learning memes), click on the “Code” button on top of this webpage!\n","date":1589068800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589068800,"objectID":"a97a1d298d3c97e3b6297a47d0ac82d2","permalink":"https://michaelkarpe.github.io/kaggle-competitions/nyc-taxi/","publishdate":"2020-05-10T00:00:00Z","relpermalink":"/kaggle-competitions/nyc-taxi/","section":"kaggle-competitions","summary":"UC Berkeley IEOR 242 Spring 2020 Kaggle Competition Winner","tags":null,"title":"★ NYC Taxi Trip Duration Prediction","type":"kaggle-competitions"},{"authors":["Michaël Karpe","Emilien Etchevers","Kieran Janin","Remi Le Thai","Haley Wohlever"],"categories":null,"content":" “Wow, we won a Kaggle competition!” That’s pretty much the reaction Emilien Etchevers, Kieran Janin, Remi Le Thai, Haley Wohlever and I got when the results of the Google Cloud \u0026amp; NCAA March Madness Analytics competition were announced.\nIn this Kaggle competition, we aimed to understand the factors contributing to the entertainment, or madness, of a college basketball match using two sources: objective data on NCAA teams’ previous performances, and subjective data on fans’ reactions to games. For the purposes of this project, two dependent variables related to the madness were explored: predictability in March Madness matches, and the corresponding distribution of viewers’ sentiment.\nClick on the “Code” button on top of this webpage to discover our analysis!\n","date":1588204800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588204800,"objectID":"08e8f205341ef48c156f95a943aa3b05","permalink":"https://michaelkarpe.github.io/kaggle-competitions/march-madness/","publishdate":"2020-04-30T00:00:00Z","relpermalink":"/kaggle-competitions/march-madness/","section":"kaggle-competitions","summary":"Google Cloud \u0026 NCAA® March Madness Analytics Kaggle Competition Winner","tags":null,"title":"★ Madness at Home and on the Court","type":"kaggle-competitions"},{"authors":["Michaël Karpe","Guillaume Desforges","Matthieu Roux"],"categories":null,"content":" Introduction In machine learning, the process of fitting a model to the data requires to solve an optimization problem. The difficulty resides in the fact that this optimization quickly becomes very complex when dealing with real problems. The Stochastic Gradient Descent (SGD) is a very popular algorithm to solve those problems because it has good convergence guaranties. Yet, the SGD does not have a good stopping criteria, and its solutions are often not accurate enough.\nThe Stochastic Dual Coordinate Ascent (SDCA) tries to solve the optimization problem by solving its dual problem. Instead of optimizing the weights, we optimize a dual variable from which we can compute the weights and thus solve the former. This method can give good results for specific problems : for instance, solving the dual problem of the SVM has proven to be effective and to give interesting results, with a linear convergence in some cases.\nIn this report, we compile the key theoretical points necessary to have a global understanding of the SDCA. First we introduce the SDCA and its principles. We then present the machine learning problem our report focuses on, and we study computational performances of the method by trying to apply SDCA on concrete problems. Finally we conclude on SDCA strengths and weaknesses.\nPurpose of the report: a new SGD-like method Difference between SGD and SDCA A simple approach for solving Support Vector Machine learning is Stochastic Gradient Descent (SGD). SGD finds an $\\epsilon_P$-sub-optimal solution in time $O(1/(\\lambda \\epsilon_P))$. We say that a solution $w$ is $\\epsilon_P$-sub-optimal if $P(w) - P(w^{*}) \\leq \\epsilon_P$, where $P$ is the objective function of the primal problem. This runtime does not depend on $n$ and therefore is favorable when $n$ is very large. However, as explained in the studied articles, the SGD approach has several disadvantages:\nit does not have a clear stopping criterion it tends to be too aggressive at the beginning of the optimization process, especially when $\\lambda$ is very small while SGD reaches a moderate accuracy quite fast, its convergence becomes rather slow when we are interested in more accurate solutions Therefore, an alternative approach is Dual Coordinate Ascent (DCA), which solves the dual problem instead of the primal problem.\nFormulation of SDCA optimization problem Let $x_1, \\dots, x_n \\in \\mathbb{R}^d$, $\\phi_1, \\dots, \\phi_n$ scalar convex functions, $\\lambda \u0026gt; 0$ regularization parameter. Let us focus on the following optimization problem:\n$$\\min_{w \\in \\mathbb{R}^d} P(w) = \\left[ \\dfrac{1}{n} \\sum_{i=1}^n \\phi_i(w^\\top x_i) + \\dfrac{\\lambda}{2}||w||^2 \\right]$$\nwith solution $w^{*} = \\arg \\min_{w \\in \\mathbb{R}^d} P(w)$.\nMoreover, we say that a solution $w$ is $\\epsilon_P$-sub-optimal if $P(w) - P(w^{*}) \\leq \\epsilon_P$. We analyze here the required runtime to find an $\\epsilon_P$-sub-optimal solution using SDCA.\nLet $\\phi_i^{*} : \\mathbb{R} \\rightarrow \\mathbb{R}$ be the convex conjugate of $\\phi_i$ : $\\phi_i^{*}(u) = \\max_z (zu-\\phi_i(z))$. The dual problem of … is defined as follows:\n$$\\max_{\\alpha \\in \\mathbb{R}^n} D(\\alpha) = \\dfrac{1}{n} \\sum_{i=1}^n -\\phi_i^{*}(-\\alpha_i) - \\dfrac{\\lambda}{2}||\\dfrac{1}{\\lambda n}\\sum_{i=1}^n \\alpha_ix_i||^2$$\nwith solution $\\alpha^{*} = \\arg \\max_{a \\in \\mathbb{R}^n} D(\\alpha)$.\nMoreover, if we define $w(\\alpha) = \\frac{1}{\\lambda n} \\sum_{i=1}^n \\alpha_ix_i$, thanks to classic optimization results, we then have:\n$$w(\\alpha^{*}) = w^{*}$$\n$$P(w^{*}) = D(\\alpha^{*})$$\nWe also define the duality gap as $P(w(\\alpha)) - D(\\alpha)$. The SDCA procedure is described in Section 1.4.\nFocus on the logistic regression In order to fully grasp the method behind the first paper, let’s take an example with the logistic regression. We will consider logistic regression only for binary classification. We use the following usual notations : $X \\in \\mathbf{X} = \\mathbb{R}^p$ the random variable for the description space, and $Y \\in \\mathbf{Y} = \\{-1, 1\\}$ the random variable for the label. We recall that the model is the following :\n$$\\frac{\\mathbb{P}(y=1 | X=x)}{\\mathbb{P}(y=-1 |X=x)} = w^\\top x, \\quad w \\in \\mathbb{R}^p$$\nWe want to find $w$ such that it maximizes the likelihood, or log-likelihood, with a term of regularization:\n$$\\min_w C \\sum_i \\log\\left(1 + e^{-y_iw^\\top x_i}\\right) + \\frac{1}{2} w^\\top w$$\nIn order to get the dual problem, we rewrite it with an artificial constraint $z_i = y_iw^Tx_i$, and we have the following Lagrangian :\n$$\\mathcal{L}(w, z, \\alpha) = \\sum_i (C \\log\\left(1+z_i\\right) + \\alpha_i z_i) - \\sum_i \\alpha_i e^{-z_i} + \\frac{1}{2}w^\\top w$$\nWe will note $w^* = \\sum_i \\alpha_i y_i x_i$ and $z^*$ the variables solution of the optimization problem\n$$\\min_{w, z} \\mathcal{L}(w, z, \\alpha) = \\mathcal{L}(w^, z^, \\alpha) = \\psi(\\alpha)$$\nIn fact, it leads to the following dual problem :\n$$\\max_{\\alpha} \\sum_{i \\in I} (-\\alpha_i \\log(\\alpha_i) - (C-\\alpha_i) \\log(C - \\alpha_i)) - \\frac{1}{2} …","date":1529020800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1529020800,"objectID":"6b14331ed22f20c36f1e275bf06e668a","permalink":"https://michaelkarpe.github.io/machine-learning-projects/sdca/","publishdate":"2018-06-15T00:00:00Z","relpermalink":"/machine-learning-projects/sdca/","section":"machine-learning-projects","summary":"An alternative to Stochastic Gradient Descent for high-dimensional data","tags":null,"title":"Stochastic Dual Coordinate Ascent","type":"machine-learning-projects"},{"authors":["Michaël Karpe","Marc-Antoine Augé"],"categories":null,"content":" Mean Shift The Mean Shift algorithm is a non-parametric technique whose aim is to find local maxima in a high-dimensional data distribution without computing the latter. Therefore, the main issue is how to efficiently estimate a density function given a set of samples.\nThe simpliest way is to smooth the data. A common technique to smooth data is to compute a kernel density estimation $f(\\mathbf{x})$:\n$$f(x) = \\sum_{i \\in \\mathcal{I}} K(\\mathbf{x}-\\mathbf{x_i}) = \\sum_{i \\in \\mathcal{I}} k\\left(\\dfrac{||\\mathbf{x}-\\mathbf{x_i}||^2}{h^2}\\right)$$\nwhere $(x_i)_{i \\in \\mathcal{I}}$ are the input samples, $k$ the kernel function and $h$ the kernel width. Then, we can find $f(x)$ maxima with usual optimization techniques (e.g. gradient ascent).\nHowever, $f(x)$ computation can have a too high complexity in high dimensional spaces. Thus, mean shift becomes useful. The algorithm uses a technique called multiple restart gradient descent, starting from $y_0$ and iterating under the following procedure (where $G$ is associated with the kernel function $g(r)=-k’(r)$):\n$$\\mathbf{y}_{k+1} = \\mathbf{y}_k + \\mathbf{m}(\\mathbf{y}_k)$$\n$$\\text{with} \\quad \\mathbf{m}(\\mathbf{x}) = \\dfrac{\\sum_{i \\in \\mathcal{I}} \\mathbf{x_i}G(\\mathbf{x}-\\mathbf{x_i})}{\\sum_{i \\in \\mathcal{I}} G(\\mathbf{x}-\\mathbf{x_i})} - \\mathbf{x} \\quad \\text{called the mean shift vector}$$\nOne-dimensional visualization of the kernel density estimate, its derivative, and a mean shift. It has been proven that this algorithm converges if the kernel $k(r)$ is monotonically decreasing. Two kernels commonly used for the mean shift algorithm are the Gaussian kernel, and the Epanechnikov kernel, whose formula is $k_{E}(r) = \\max(0,1-r)$. Therefore, the simpliest way to apply mean shift algorithm is to use the above gradient procedure at every input point $x_i$, in order to find all local maxima.\nIn image segmentation, mean shift algorithm is generally used taking into account spatial coordinates and color of pixels, as with the bilateral filter, through a kernel of the form:\n$$K(\\mathbf{x_i}) = k\\left(\\dfrac{||\\mathbf{x_r}||^2}{h_r^2}\\right)k\\left(\\dfrac{||\\mathbf{x_s}||^2}{h_s^2}\\right)$$\nwhere $\\mathbf{x_s} = (x,y)$ are the spatial coordinates (spatial domain), $\\mathbf{x_r}$ is the color value (range domain), $h_s$ (resp. $h_r$) the spatial (resp. range) bandwith.\nNormalized Cut The Normalized Cut algorithm is an efficient way to segment an image. This algorithm is based on a graph representation of the image: pixels are vertices and weights (edges) depend on the image (brightness, intensity, distance or whatever can be useful to segment the image). The vertices could be just a subset of pixels like points of interest.\nOnce the graph is computed, the problem is to cut vertices into two disjoint subsets $A$ and $B$ such that weights from A to B, $cut(A, B) = \\sum_{u \\in A, v\\in B} w(u, v)$ is minimal. Unfortunately, algorithms tend to make unbalanced sets ($cut(A, B)$ is smaller if $A$ contains only one element). The idea for this algorithm is to \\textit{normalize the cut}:\n$$N_{cut}(A, B) = \\frac{cut(A, B)}{assoc(A, V)} + \\frac{cut(A, B)}{assoc(B, V)}$$\nwhere $assoc(A, V) = \\sum_{u \\in A, t \\in V} w(u, t)$.\nIt has been proven in reference 1 that the normalized cut is equivalent to find the eigenvector with the second smallest eigenvalue for:\n$$(D - W)x = \\lambda Dx$$\nwhere, if $N = |V|$, $W \\in \\mathbb{R}^{N\\times N}$ is the weight matrix and $D \\in \\mathbb{R}^{N\\times N}$ is the diagonal matrix where $D(i, i) = \\sum_j w(i, j)$. Signs of the second eigenvector $x$ decide on the cut ($i \\in A$ iff $x(i) \u0026gt; 0$).\nOur results: We decided to test this algorithm. Firstly, we worked on a set of points in $\\mathbb{R}^2$ and we made a graph where vertices are points and weights are $w(x,y) = ||x - y||_2^{-1}$. We obtained the segmentation shown in the left figure below, which give good results (the algorithm did not know the colors / the labels of the points). Then, we decided to work on artificial images and we found two main issues:\nHow can we make efficiently (in Python) the graph from the image? How can we speed up the algorithm (because the complexity is $O(N^3)$ where $N = |V|$, $N = 10^6$ for a $1000\\times 1000$ image)? To solve the first issue, we decided to make a graph only based on colors, i.e. $w(x, y) = np.abs(I(x) - I(y))$. To solve the second one, we used a sparsed matrix. We obtained great results for two artificial black and white images but results are awful for real images. Therefore the idea is to change our graph representation.\nResults for the cut of two gaussians. Perfect results for an artificial and complex B\u0026amp;W picture. Failure with a real photograph (coins). References Shi, J., \u0026amp; Malik, J. (2000). Normalized cuts and image segmentation. IEEE Transactions on pattern analysis and machine intelligence, 22(8), 888-905.\nSzeliski, R. (2010). Computer vision: algorithms and applications. Springer Science \u0026amp; Business Media.\n","date":1527638400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527638400,"objectID":"9157c38249b4c09b71acadcc66ff3dad","permalink":"https://michaelkarpe.github.io/computer-vision-projects/segmentation/","publishdate":"2018-05-30T00:00:00Z","relpermalink":"/computer-vision-projects/segmentation/","section":"computer-vision-projects","summary":"Presentation of two image segmentation techniques","tags":null,"title":"Image Segmentation: Mean Shift \u0026 Normalized Cut","type":"computer-vision-projects"},{"authors":["Michaël Karpe","Hervé Andres","Mohamed Bouazza","Melvin Casanave"],"categories":null,"content":" Brief description of the project During the Spring semester of my second year at École des Ponts ParisTech (from February 2018 to May 2018), I worked with three other students on a credit card fraud detection project for Société Générale.\nThe aim of this project was to realize a comparative study between different outlier detection algorithms to select the one that had the best performances on a credit card fraud dataset. After some research, we decided to focus our study on the following algorithms:\nRobust Estimator of Covariance Local Outlier Factor One-class SVM Isolation Forest Autoencoder The code is available on my GitHub but has been left uncleaned.\nRelated project In June 2019, Robin Teuwens shared a kernel on the famous Kaggle Credit Card Fraud Dataset, entitled Fraud Detection as a Cost Optimization Problem (Teuwens changed the name of kernel in August) and proposing an approach very similar to ours.\nIndeed, the image at the beginning of this article shows profits and costs we had chosen for the cost function we wanted to minimize for the Societe Generale project, according to the predicted and the real label of a given transaction.\nIn November 2019, I made some changes to Teuwens’ kernel to improve his results, switching the logistic regression to gradient boosted trees algorithms and SMOTE oversampling to ADASYN oversampling.\nIf I have some time in the next months (but it’s unlikely as I switched to new projects), I would like to evaluate the performance of autoencoders on this latest kernel, as we used them for the Societe Generale project and as Teuwens also proposed a kernel using autoencoders.\n","date":1527206400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527206400,"objectID":"3b18a524f560ed6c33f03367d7d4f894","permalink":"https://michaelkarpe.github.io/machine-learning-projects/outlier/","publishdate":"2018-05-25T00:00:00Z","relpermalink":"/machine-learning-projects/outlier/","section":"machine-learning-projects","summary":"Fraud Detection as a Cost Minimization problem","tags":null,"title":"★ Credit Card Fraud Detection","type":"machine-learning-projects"},{"authors":["Michaël Karpe","Maxime Duval"],"categories":null,"content":" Relocation vectors Calculation The visualization of the relocation vectors is obtained by plotting the segments between the generators before and after Lloyd’s iteration. The generators of the cells in the previous iteration have been drawn in red.\nVisualization of relocation vectors. Visualization of the cells after convergence. Convergence For the plotting of the convergence curves, we saved the different values in .txt files and processed the data in Python language, with the matplotlib.pyplot library. We can see that this evolution is globally decreasing, with an increase in energy when the cells “unblock” after having converged to a local minimum of energy.\nEvolution in logarithmic scale of the mean norm of the relocation vectors as a function of the number of Lloyd’s iterations for a uniform initialization. Evolution in logarithmic scale of the mean norm of the relocation vectors as a function of the number of Lloyd’s iterations for an initialization in one corner. Evolution in logarithmic scale of the mean norm of the relocation vectors as a function of the number of Lloyd’s iterations for an initialization on a line. By zooming the first convergence curve between $30$ and $60$ iterations and plotting it in real scale (and not in logarithmic scale as on the different images), it becomes clear that the convergence of the mean length is quadratic.\nVisualization of the sampling of the square domain with $N = 10 000$ points. Energy distribution by cell Calculation The global energy of a domain partition in $N_c$ cells $\\mathcal{C}_i$ is given by the following formula :\n$$E_{dom} = \\sum_{i=1}^{N_c} E_{cell} = \\sum_{i=1}^{N_c} \\int_{x \\in \\mathcal{C}_i} ||x-x_i||^2 dx$$\nTo carry out the calculation of integrals, we proceed by Monte-Carlo method, by sampling a number $N$ of points $x_j$ on the whole domain and by approximating the integral by a discrete sum :\n$$E_{cell} = \\int_{x \\in \\mathcal{C}i} ||x-x_i||^2 dx = \\sum{x_j \\in \\mathcal{C}_i} ||x_j-x_i||^2$$\nA representation of this sampling is shown for $N = 10,000$. In order to cover the entire domain sufficiently, we have chosen $N = 100,000$.\nVisualization of cells after convergence in an hourglass-shaped domain. Convergence Still in the square domain with an initialization of $10$ points, the evolution of the energy of the cells is represented below. For the $3$ initializations tested, we can see that the cells converge to a close energy after about thirty iterations. This convergence is fast for uniform and one-line initializations, with a slight energy correction at about $23$ iterations for the uniform initialization, due to the cells getting stuck (which we find with the growth of the average norm of the relocation vectors around the same number of iterations).\nFor initialization in a corner, convergence is slower because more iterations are needed to allow the $10$ generators to occupy the entire domain space. However, there is no major energy jump due to a blockage of cells between them.\nEvolution of the average energy of the cells as a function of the number of Lloyd’s iterations for a uniform initialization. Evolution of the average energy of the cells as a function of the number of Lloyd’s iterations for an initialization in a corner. Evolution of the average energy of the cells as a function of the number of Lloyd’s iterations for an initialization on a line. Domain influence The shape of the domain greatly influences the convergence results. For example, for the circular domain, which is a “regular” domain in the sense that the edges do not have “corners” or abrupt breaks in direction (the edges are well continuous and driftable), convergence occurs without any problem after about ten iterations and is not characterized by any particular jumps. The results for the circular domain are shown below.\nVisualization of cells after convergence in a circular domain. Evolution of the mean norm of relocation vectors in a circular domain as a function of the number of Lloyd’s iterations for uniform initialization. Evolution of the mean cell energy in a circular domain as a function of the number of Lloyd’s iterations for uniform initialization. For the other areas provided, more original behaviour can be observed, due to the same observations as those made previously. For the L-shape, the inner corner of the L will cause some increases in average length, as the cells “crossing” the corner move quickly at once to adapt to the shape, and convergence is quite slow relative to the square and circular shapes.\nFor the key-shaped domain, convergence is also slower due to the complexity of the domain, and medium-length jumps are more important due to this complexity, because cells move a lot when a “corner” is crossed and filled by the cells.\nVisualization of cells after convergence in a L domain. Visualization of cells after convergence in a domain containing a cross. Visualization of cells after convergence in a domain in the form of a key. Evolution of the …","date":1525651200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1525651200,"objectID":"bf80c2bc257e6e85f97ccc0ddab9cb87","permalink":"https://michaelkarpe.github.io/computer-vision-projects/lloyd/","publishdate":"2018-05-07T00:00:00Z","relpermalink":"/computer-vision-projects/lloyd/","section":"computer-vision-projects","summary":"Study of the convergence depending on the parameters of the algorithm","tags":null,"title":"★ Lloyd Iteration Convergence","type":"computer-vision-projects"},{"authors":["Michaël Karpe","Bastien Déchamps"],"categories":null,"content":" Presentation of the project In the field of translationology, there are many approaches and algorithms for making translations from one language to another. Each method has its advantages and disadvantages, and a compromise between several methods is usually needed to achieve an efficient translation algorithm.\nWe are interested here in an algorithm for aligning texts in different languages based on dynamic time warping (DTW). Such an algorithm does not require either prior bilingual resources or knowledge of similarities between the languages studied.\nIt can thus work on any language pair, especially on languages for which few linguistic resources are available. On the other hand, its accuracy in translation is low, so we will focus mainly on aligning paragraphs rather than words.\nThe approach used in Kim Gerdes’ algorithm, although simple at first glance, is no less original. It consists in working on the occurrences and position of words in the texts under consideration using the DTW.\nParagraph alignment The application of DTW in a translation system can make bad associations, if one tries to be too precise, due to different syntaxes within languages. The algorithm proposed by Gerdes therefore uses the sum of the word alignments to align paragraphs, thus eliminating possible spurious signals due to erroneous word associations.\nLength-based alignment is an alignment method, not based on the DTW, which allows a first alignment of paragraphs based solely on the length of the paragraphs.\nJaro-Winkler distance To complete the DTW distance, we use the Jaro-Winkler syntax distance between $2$ strings $d_w$ , depending on the Jaro distance $d_j$:\n$$ d_w = d_j+lp(1-d_j) \\qquad \\text{ with } \\qquad d_j = \\frac{1}{3}\\left(\\frac{m}{|s_1|} + \\frac{m}{|s_2|} + \\frac{m-t}{m}\\right) $$\n$|s_{i}|$ is the length of the string $s_{i}$ $m$ is the number of corresponding characters $t$ is the number of transpositions $l$ is the length of the common prefix (maximum $4$ characters) $p$ is a coefficient that allows to favor strings with a common prefix (Winkler proposes for value $p = 0.1$) Dynamic Time Warping (DTW) In general, DTW algorithms seek to find the optimal monotonic (non-intersecting) alignment of two sequences of variable length. Monotonic means that the order of the sequence positions before and after DTW is respected, but that the distance between these positions may change. \\newline\nDTW algorithms are dynamic programming algorithms. For our paragraph alignment, it is applied on recency vectors $(p_1, p_2-p_1, \\dots, p_n-p_{n-1}, 1-p_n)$ where $p_i$ is the position of the $i$ occurrence (in text fraction) of the considered $p$ word.\n$$ W_{i+1,j+1} = \\left| r_1-r_2 \\right| + \\min\\left(W_{i,j+1}, W_{i+1,j}, W_{i,j}\\right) $$\nIntegration in an alignment system We describe here, in a synthetic way, the global algorithm performing the automatic matching of texts in different languages without prior knowledge, including the DTW algorithm explained above. This algorithm, described in detail by Kim Gerdes, can be synthesized in $4$ main steps:\nReading and cleaning of texts: suppression of parasitic signals (accents, extra spaces, punctuation…) Construction of hash tables associating words with their different characteristics (number of occurrences, appearance indices…) Calculation for each of the texts of the internal cognates of the language (Jaro-Winkler distance), significant words or groups of words (frequent and well distributed in the text). Application of the DTW algorithm for the alignment of words, groups of words and paragraphs Execution of the alignment system The alignment system described above was developed in C++ and applied to the Universal Declaration of Human Rights (UDHR) in the following languages: English, French, Spanish, German, Russian. We present here the results obtained for the French-English language pair.\nFrench English DTW French English DTW respect respect 0.0039 nations nations 0.0228 ces these 0.0046 conscience conscience 0.0245 déclaration declaration 0.0070 dignité dignity 0.0306 sans without 0.0107 religion religion 0.0326 considérant whereas 0.0115 éducation education 0.0375 nationalité nationality 0.0116 contre against 0.0383 libertés freedoms 0.0124 article article 0.0545 famille family 0.0150 droits rights 0.0714 société society 0.0152 présente declaration 0.0849 unies united 0.0213 religion property 0.0979 Analysis of the results After applying the DTW algorithm to different languages, we found that word matching was effective when the DTW value returned for a word pair was less than $0.1$ (this value having been normalized to be between $0$ and 1).\nFor the French and English language pair, we find erroneous associations for DTW values greater than $0.08$, notably due to the different syntax of the languages (see below). It is therefore necessary to include the Jaro-Winkler distance in the alignment system to correct this problem.\nOnce the Jaro-Winkler distance is included in the …","date":1517788800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1517788800,"objectID":"74f4eda7e7d5291b1d9ec0cc9e4d25a3","permalink":"https://michaelkarpe.github.io/optimization-projects/textmatching/","publishdate":"2018-02-05T00:00:00Z","relpermalink":"/optimization-projects/textmatching/","section":"optimization-projects","summary":"Text matching from different languages without prior knowledge","tags":null,"title":"★ Automated Text Matching","type":"optimization-projects"},{"authors":["Michaël Karpe","Hervé Andres","Mohamed Bouazza","Claire Zeng"],"categories":null,"content":" Presentation of the project Determining the dependency structures between different assets or risk factors is at the heart of multidimensional financial modelling problems. For example, when considering a portfolio of assets, Markowitz theory states that it is important that the portfolio be diversified and therefore that the assets be as uncorrelated as possible.\nMathematically, the natural variable to model this dependence structure is the covariance matrix. Indeed, in the context of Gaussian variables, covariance is sufficient to describe correlation structures (which is not the case for other distributions). Moreover, although the focus is on covariance and the criterion studied is based on Gaussian modelling, the information obtained is actually richer and can be applied to other distributions.\nHowever, the empirical data that we exploit are affected by noise that biases the estimation and conventional methods then provide poor results.\nPurpose and method of resolution The aim is therefore to obtain a noise-free covariance matrix, called sparse due to a large number of zero coefficients, from a noisy covariance matrix. This problem can be written as an optimization problem in which one seeks to maximize the log-likelihood of the solution by penalizing the number of zeros in the inverse covariance matrix. In addition, we impose constraints on its eigenvalues to ensure that the matrix is positive, and to further limit the solution, given the information that we would have a priori on the problem. In the Gaussian framework, the latter is formulated as follows:\n$$\\text{max} \\ f(X) := \\log \\det X - \u0026lt; \\Sigma, X \u0026gt; - \\rho \\ Card(X)$$ $$\\text{s.c.} \\ \\alpha I_n \\leq X \\leq \\beta I_n$$ $$\\Sigma \\in S_n^{+}, \\ X \\in S_n$$ $$\\rho, \\ \\alpha, \\ \\beta \u0026gt; 0$$\nHowever, this problem is described as NP-difficult, which means that it cannot be solved by computer in a reasonable time - one reason for this is the non-convexity of the objective function. It is therefore necessary to transform it. For this, convex relaxation methods are applied to the initial problem. These methods make it possible to put the problem into a form for which numerical solving algorithms exist. The algorithm used here is the algorithm of Nesterov (2005).\nNesterov’s algorithm Nesterov’s algorithm is based on recent and efficient optimization methods to determine the extremum of a function $\\phi(y)$ which is close to the function $f(X)$. By reducing the difference between the exact solution and the approximated solution by successive iterations (see figure below), we obtain a result very close to the exact solution.\nIllustration of the Nesterov algorithm with $f(x)$ exact function, $\\phi(y)$ approximate function. Checking the algorithm In order to make sure that the algorithm is properly implemented, we tested it on a very simple noisy matrix. It was constructed as follows:\nStep 1: An $A$ matrix is constructed whose diagonal coefficients are equal to 1 and of which a few non-diagonal coefficients (i.e. a negligible number compared to the size of the chosen matrix), randomly drawn according to a uniform probability, are equal to $1$ or $-1$ with equiprobability. The randomly drawn non-diagonal coefficients are copied symmetrically with respect to the diagonal so as to obtain a diagonal matrix. If the resulting matrix is not invertible, the procedure is repeated. The matrix finally created corresponds to the inverse of a covariance matrix without noise but with some non-zero covariances, i.e. only a few variables are correlated.\nMatrix $A$ from step 1. Step 2: A second $V$ matrix whose coefficients follow a uniform law on $[-1, 1]$ is constructed and then symmetrized. This matrix corresponds to the noise.\nStep 3: We constitute a covariance matrix $B$ noise by summing the inverse of $A$ with $\\sigma V$ where $\\sigma$ allows to intensify or to attenuate the noise.\nMatrix $B$ from step 3. We applied Nesterov’s algorithm to this test matrix with $\\epsilon = 10^{-5}$, $\\rho = 0.5$, $\\alpha = 10^{-1}$, $\\beta = 10$ and $\\sigma = 0.15$.\nMatrix obtained by applying Nesterov’s algorithm to $B$. In order to present the results obtained by the Nesterov algorithm for the test matrix, we represent the matrices at the input and output of the algorithm by arrays of pixels where each pixel has a color that depends on the value of the coefficient with which it is associated.\nThe results obtained are very satisfactory. Indeed, the matrix obtained by the algorithm looks very much like the initial noiseless matrix.\nApplication to interest rate analysis We then applied our algorithm to a covariance matrix obtained empirically from data on interest rate changes.\nNoisy empirical covariance matrix. Selected covariance matrix. After applying the algorithm, the selected matrix has a globally diagonal block structure. To interpret this structure, a graphical representation is used where the nodes are the different assets and an edge is drawn between two nodes if they are …","date":1508112000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508112000,"objectID":"fa06f9b4fbcc1883b1f1471d73ef723b","permalink":"https://michaelkarpe.github.io/quantitative-finance-projects/covariance/","publishdate":"2017-10-16T00:00:00Z","relpermalink":"/quantitative-finance-projects/covariance/","section":"quantitative-finance-projects","summary":"Identifying clusters of correlated variables","tags":null,"title":"Covariance estimation by sparse method","type":"quantitative-finance-projects"},{"authors":["Michaël Karpe","Arnaud Sadaca","Nada Soussi","Claire Zeng"],"categories":null,"content":" Presentation of the project The acquisition of a digital image is most often accompanied by the appearance of noise, often due to imperfections in the detection, transmission or compression of the signal, or to inherent defects in the environment such as insufficient or too much lighting. The suppression of this noise is even a vital issue in several fields, including medical imaging, and the search for an effective image denoising algorithm remains a persistent challenge at the crossroads of several scientific fields: functional analysis, probability, statistics and physical sciences.\nIn this study, we implement different algorithms for the restitution of an image containing simple grayscale patterns, noisy according to Gaussian noise. For this, we adopt a probabilistic description of the image, considering its pixels as random variables $X_i$, energy $U(X_i)$ which depends on its neighborhood. This approach allows us to consider the image as a Markov field.\nNumerical implementation of Markov fields We are now formulating the probabilistic methods that we have digitally implemented to apply them to image processing.\nIn our study, we will consider rectangular grayscale images (0 to 255), length $w$ and height $h$. Each pixel in the image is represented by its coordinates $(i, j)$ and a value corresponding to the gray level of the pixel, which value belongs to $E = [|0, 255|]$. The total image can thus be represented by an array of values of $E$, of dimension $w \\times h$.\nFor each pixel, a click system can be defined as represented on the first image of this article. In our computer codes, the presence of a variable $c$ which will take the value $4$ or $8$ will allow us to choose if we consider $4$ or $8$-connected neighborhoods, and we will consider clicks of order $2$.\nThe implementation of image processing algorithms has three main phases:\nthe choice of a suitable Markov field the drawing of a configuration according to the chosen Markov field the implementation of the algorithm that converges to a correct image after a certain number of prints. We describe these three phases in a theoretical way, then we will analyze the results obtained with the different methods.\nMarkov fields in image processing We present here the most used Markov fields in image processing as well as some variants giving better results.\nIsing Model The Ising model is only applicable to an image with $2$ levels of gray. By an affine transformation, we can associate to these $2$ values the values of the set $E = \\{-1, 1\\}$. We recall the energy of this model:\n$$U(x) = - \\sum_{c=(s,t) \\in C} \\beta x_s x_t - \\sum_{s \\in S} B x_s$$\nPotts Model This is a generalization of Ising’s model, adapted to a set $E$ of cardinal $N$, as $E = [|0, 255|]$. The main difference with the Ising model is that only potentials related to second-order clicks are defined. There is no energy term related to first-order clicks, corresponding to an external magnetic field. The energy of this model is :\n$$U(x) = \\ \\beta \\sum_{c=(s,t) \\in C} (\\textbf{1}{\\{x_s \\neq x_t\\}} - \\textbf{1}{\\{x_s = x_t\\}})$$\nSuch a model tends to create homogenous zones the larger the $\\beta$ is.\nGaussian Markovian model This model can only be used for grayscale images, which is perfectly suited to our study. We consider, here again, $4$- or $8$-axis neighborhoods and only second order clicks. The energy of this model is :\n$$U(x) = \\beta \\sum_{c=(s,t) \\in C} (x_s-x_t)^2 + \\alpha \\sum_{s \\in S} (x_s-\\mu_s)^2$$\nFor $\\beta \u0026gt; 0$, the first quadratic term favors small differences in gray level, since it minimizes an energy that increases quadratically with the difference in gray levels. The second term involves a $\\mu_s$ term that corresponds to a reference image. If we know an approximation of the image we want to obtain, or if we want to remain close to the initial image, this term allows the solution image $x$ to not move away from the reference image $\\mu$.\nDrawing a configuration according to the Markov field Once a Markov field has been chosen, its total energy must be minimized. This is done by pulling configurations. The general idea is to draw a random value for each pixel and to assign it this value if it allows the total energy to be reduced.\nThe algorithms most commonly used to make these draws, the Gibbs sampler and the Metropolis algorithm, work in a similar way. The $n$ iterations, where a $s$ pixel is randomly selected and then an image-dependent random experiment is associated with $s$ at the $n-1$ iteration. We update or not $s$ depending on the result of the random experiment.\nSince all the pixels $s$ must be scanned a large number of times, one usually scans all the pixels line by line and from left to right without performing a random draw, to make sure that all pixels have been updated. The algorithm stops after a large number $n$ of iterations, or when there are few pixel changes for an iteration.\nBoth algorithms are called probabilistic relaxation algorithms: …","date":1496793600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1496793600,"objectID":"becdb071f295cb06bab7b5f862303c2a","permalink":"https://michaelkarpe.github.io/computer-vision-projects/restoration/","publishdate":"2017-06-07T00:00:00Z","relpermalink":"/computer-vision-projects/restoration/","section":"computer-vision-projects","summary":"Image deblurring with Markov Random Fields","tags":null,"title":"Markovian Image Restoration","type":"computer-vision-projects"},{"authors":["Michaël Karpe","Bastien Déchamps"],"categories":null,"content":" Presentation of the project This project was carried out during a programming course at École des Ponts ParisTech. The goal of this project was to create in pairs and in about thirty hours a simple game based on the C++ language.\nWe wanted to reproduce a Zuma game, as illustrated above, focusing on the algorithmic functioning of the game - graphics not being the priority of a C++ programming course, as you will see at the end of the article…\nPrinciple of the game “Zuma is a video game developed by PopCap Games, released in 2003. […] The goal is to form chains of balls of the same colour (which has the effect of making them disappear) before the balls arrive in the hole in the middle. The more levels progress, the more balls of different colours, the faster they go and the more courses there are. It is also possible to collect various bonuses (coins, various objects) that increase the score, and some balls have special powers (explosive, slowing down the game, etc.)”. (Reference: French Wikipedia)\nThus for each level of the game, a global initialization of the level is made with the sending of a snake of balls, and the end of the level is defined according to certain criteria of difficulty: number of balls per snake, number of snakes, number of colors of balls, speed of movement of the snakes…\nAs long as the level is not finished, you have to manage :\nthe movement of the snakes the ball shot inserting the ball into the snake destruction of marbles if necessary ($3$ marbles or more of the same color aligned) the sending of another snake under conditions Making the game in C++ Our main objective was to reproduce the scrolling of the log snakes around the frog, as well as the shooting of the frog’s logs to eliminate the log snakes. To do this, we created different classes briefly described below :\nzuma: launch and general operation of the game frog: choice of shooting ball and shooting of balls snake: creating and moving snakes, adding and destroying beads. ball: creation and movement of balls level : difficulty criteria of the current level (number of balls, snakes, colors, speed…) trajectory : path on which the snakes of marbles move tools: global functions and parameters Expectation vs. reality Although the game was operational at the end of the time limit, we didn’t have time to work on the graphics…\n","date":1496361600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1496361600,"objectID":"4f90004b78924848c17019014287e552","permalink":"https://michaelkarpe.github.io/programming-projects/zuma/","publishdate":"2017-06-02T00:00:00Z","relpermalink":"/programming-projects/zuma/","section":"programming-projects","summary":"Build a simplified Zuma video game in C++ and 30 hours","tags":null,"title":"Simplified Zuma video game","type":"programming-projects"},{"authors":["Michaël Karpe","Hervé Andres","Marc-Antoine Augé","Reda Bahi Slaoui","Imad Lakim"],"categories":null,"content":" Presentation of the project As part of the management of the assignment of first year students to second semester courses and projects at Ecole des Ponts, we were asked to design a computer program that manages the assignment of students to courses. In order to meet the requirements of the first year department, this program must comply with a number of constraints.\nOur objective is to optimize the process of assigning students to courses and projects, by proposing a distribution of students that respects as much as possible the ranking of their wishes. Indeed, we have three main sets of courses and projects:\nthe department projects: there are $20$ projects in $2017$ and they take place on Monday afternoons. the opening courses: they are spread over $4$ days, each day having a well-specified set of courses that the students have to classify. introductory research projects: these are associated with the opening classes. Each opening course has a project on the same theme. As a result, every student must necessarily be assigned to a project that is associated with one of the courses he or she is taking. In addition, each course and each project has a maximum number of students and a minimum number of students required to open the course. These numbers may vary from one course to another. Finally, some courses or projects may be discontinued if demand is not high enough.\nMathematical modelling Optimization program for a single project / course choice In order to account for the fact that a student has or has not received his first wish, we have introduced a regret function, the value of which is all the higher as the first wishes are not fulfilled. Our modeling aims at minimizing the total regret function. For a given project, the regret function of a student corresponds to the weight function evaluated at the wish number of the project. The weight function is a function that associates a number to a wish number that is higher the higher the wish number is, and is worth $0$ if it is the student’s $1$ wish. An example of a quadratic weight function ($f(x) = (x - 1)^2$) is given below :\nRank Weight 1 0 2 1 3 4 4 9 5 16 … … In order to know to which project a student is assigned, we use a matrix $A = (a_{e,p}){e,p}$ whose coefficient $a{e,p}$ is $1$ if student $e$ is assigned to project $p$ and $0$ otherwise. Given this, the regret function of a student for a given project is $\\sum_{p\\in P} a_{e,p} w(c_{e,p})$. This minimization problem comes with several constraints:\nThe enrolment of the project numbered $p$, noted $n_{p}$ and defined as the sum over the students of the assignments $a_{e,p}$, must be between the minimum $m_{p}$ and the maximum $M_{p}$ enrolment associated with this project. These bounds are multiplied by a binary variable $\\delta_{p}$ which equals $0$ if the project is closed and $1$ if it is open. Thus, if there are not enough students who have applied for a given project, that is, if it is not in the first wishes of a sufficient number of students, then the project in question will have a zero enrolment. Each student must be assigned to one project only. For this purpose, the sum of the student’s $a_{e,p}$ assignments on projects is equal to $1$. Mathematically, the problem thus modeled is written as follows:\n$$\\text{min} \\sum_{e \\in E} \\sum_{p \\in P} a_{e, p}.w(c_{e, p}) + Kr_{max}$$ $$\\text{s.t.} \\ \\forall p \\in P, \\ n_p = \\sum_{e\\in E} a_{e, p}$$ $$\\forall p \\in P, \\ \\delta_p.m_p \\leq n_p$$ $$\\forall p \\in P, \\ n_p \\leq \\delta_p.M_p$$ $$\\forall e \\in E, \\ \\sum_{p \\in P} a_{e, p} = 1$$ $$\\forall p \\in P, \\ \\delta_p \\in {0, 1}$$ $$\\forall p \\in P, \\ \\forall e \\in E, \\ a_{e, p} \\in {0, 1}$$\nSettings $J$: All days, two courses or projects on the same day cannot be cumulated. $E$: All students. $P$: Set of all projects / courses to be chosen partitioned according to days $P = \\bigcup_{j \\in J} P_j$. $C$: Matrix of students’ choices tq. $c_{e, p}$ is the rank of the project $p$ for the student $e$. $m_p$ and $M_p$: Minimum and maximum numbers for the $p$ project. $w$: Weight function. $pr$: Function that, with an opening course, associates a project of initiation to the search. $K$: Constant increasing total regret. Variables $\\delta_p = 1$ if project $p$ is open, $0$ otherwise. $A$ : Student assignment matrix tq $a_{e, p} = $1 if student $e$ is assigned to project $p$, $0$ otherwise. $n_p$ : Enrollment in project $p$. $r_{max}$ : Maximum pupil regret. May be a parameter. Optimization program for multiple project or course choices When there are several projects or courses to choose from, the allocation results must take into account each other. For example, if a student is assigned to a Wish $3$, their other assignments should correspond, as much as possible, to Wish $1$ courses. This is accomplished by adding a variable $r_{max}$ which corresponds to the maximum regret per student. Each student’s regret ($\\sum_{p \\in P} a_{e, p}w(c_{e, p})$) is therefore increased by $r_{max}$.\nIn order to …","date":1489968000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1489968000,"objectID":"f08fd276e2959e581d3e4deaec32e1d0","permalink":"https://michaelkarpe.github.io/optimization-projects/allocation/","publishdate":"2017-03-20T00:00:00Z","relpermalink":"/optimization-projects/allocation/","section":"optimization-projects","summary":"Automatic and optimal course allocation with wishlists from students","tags":null,"title":"Optimal Course Allocation","type":"optimization-projects"},{"authors":["Michaël Karpe"],"categories":null,"content":" Presentation of the project Many pool players, myself included, would dream of pocketing all the balls one after the other. However, because of the many parameters that govern the movement of the balls, this is difficult, but not impossible. So we’re going to look for the perfect trajectory in billiards to find out “how to pocket a billiard ball for sure”.\n*Since we are trying to make trajectories as predictable as possible, we will consider in our study balls moving without effect, therefore in a straight line.\nWe will first focus on an experimental study of friction, then on the theoretical study of the $3$ main physical laws governing motion, and finally I will develop the design of computer programs that will allow us to determine the perfect trajectories to pocket a ball.\nExperimental study of friction First of all, we will look at the friction of the ball with the mat, which is obviously the cause of the loss of speed of the ball. To study the evolution of this speed, I proceeded to a video scoring with the LatisPro software, after having placed a mark and a $1.82 $m standard corresponding to the length of the billiard table.\nThe software’s zoom allows for very accurate readings, however, the video has a frame rate of $30$ frames per second, so the ball only moves a few pixels between frames. The plot of the speed evolution on Excel is then rather chaotic. I then measured the position of the ball every $5$ images, to see a linear evolution of the speed, with a deceleration of $0.17$ $m.s^{-2}$, and an uncertainty on this deceleration of $0.044$ $m.s^{-2}$ obtained by the method of least squares :\n$$a = -0,170 \\pm 0,044 \\ m.s^{-2}$$\nTheoretical study of the 3 main laws of motion We are now moving on to the theoretical study to justify this constant deceleration, as well as the movement of the balls during the rebounds on the belts and during the shocks between balls.\nStudy of rebounds When considering rigid bands, bounces follow Descartes’ law of reflection, analogous to light rays in optics.\nStudy of shocks Under the hypothesis of balls evolving without effect, the shocks between balls are governed by the laws of elastic shocks, i.e. conservation of the quantity of motion and kinetic energy :\n$$\\overrightarrow{p_1} = \\overrightarrow{p_1’} + \\overrightarrow{p_2’}$$ $$\\frac{1}{2}mv_1^2 = \\frac{1}{2}mv_1’^2 + \\frac{1}{2}mv_2’^2$$\nThis involves deflecting the balls along paths forming an angle $\\alpha = 90°$.\nStudy of friction Finally, as far as friction is concerned, a distinction is theoretically made between two rolling phases. However, we will only be interested in the second phase of rolling without slip, the first phase of rolling with slip taking place only for a negligible period of time. The position of the ball during the rolling phase with slippage is given by the formula:\n$$\\overrightarrow{OG}(t) = \\overrightarrow{OG}(0) + \\overrightarrow{v_{/R}}(G, 0)t - \\frac{\\overrightarrow{v_{/R}}(I, 0)}{||\\overrightarrow{v_{/R}}(I, 0)||} \\frac{fgt^2}{2}$$\nIt is shown with the fundamental principle of dynamics and the theorem of the kinetic moment that, since the ball is rolling without slipping, one cannot neglect the force of resistance to the advance due to the sinking of the ball into the belt:\n$$\\overrightarrow{F} = -f_cmg\\frac{\\overrightarrow{v_{/R}}(G)}{||\\overrightarrow{v_{/R}}(G)||}$$\nRégis Petit, engineer-researcher, tells us in his Théorie du jeu sur le billard that this force is opposed to speed, and proportional to a coefficient $f_c$ :\n$$f_c = \\frac{\\sin(\\gamma)}{0.4 + \\cos(\\gamma)}$$\nA good approximation of this coefficient is obtained by measuring the time $t$ taken by the ball to travel the $L$ length of the billiard table, arriving at this $L$ length at zero speed:\n$$f_c \\approx \\frac{2L}{gt^2}$$\nFor our experimental billiard table, it takes $5.5$ $s$ to the ball to go through the $1.82$ $m$ arriving at zero speed, which corresponds to an angle $\\gamma = 1°$ and a coefficient $f_c = 1.25%$. These results are consistent since billiards are designed so that friction is as negligible as possible.\nTrajectory research program design Now that we know the laws governing the movement of marbles, we will be able to make computer programs that will show us the perfect trajectories to pocket a marble.\nIn order to propose predictable and easily achievable trajectories on a real billiard game, we consider that only the cue ball moves, only bouncing, and $2$ maximum. When it hits the colored ball that we want to pocket, the colored ball goes directly into the hole without rebounding.\nSearching for the set of trajectories to reach a ball As a first step, we need to carry out programs that trace the billiard table, the balls and the trajectories, so that we can check the proper functioning of our future programs.\nPerforming a graphical simulation The main plotting program I have made is a program that takes as argument a number $n$, randomly plots $n$ balls on the billiard table, and returns the list of …","date":1466985600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1466985600,"objectID":"95d6254f2be40fcb4062e5a5603222f8","permalink":"https://michaelkarpe.github.io/programming-projects/billiards/","publishdate":"2016-06-27T00:00:00Z","relpermalink":"/programming-projects/billiards/","section":"programming-projects","summary":"How to compute perfect trajectories to win a billiard game","tags":null,"title":"★ Perfect Trajectory Forecasts in Billiards","type":"programming-projects"}]